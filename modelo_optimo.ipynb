{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6cfd49d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribución completada.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# Ruta de la carpeta con las imágenes\n",
    "carpeta_origen = 'rx'  \n",
    "\n",
    "# Crear subcarpetas de destino\n",
    "for i in range(1, 5):\n",
    "    os.makedirs(os.path.join(carpeta_origen, f'carpeta{i}'), exist_ok=True)\n",
    "\n",
    "# Filtrar solo imágenes\n",
    "extensiones_validas = ('.jpg', '.jpeg', '.png', '.bmp', '.gif', '.tif', '.tiff')\n",
    "imagenes = sorted([f for f in os.listdir(carpeta_origen) if f.lower().endswith(extensiones_validas)])\n",
    "\n",
    "# Repartir equitativamente en 4 carpetas\n",
    "for i, imagen in enumerate(imagenes):\n",
    "    carpeta_destino = os.path.join(carpeta_origen, f'carpeta{(i % 4) + 1}')\n",
    "    ruta_origen = os.path.join(carpeta_origen, imagen)\n",
    "    ruta_destino = os.path.join(carpeta_destino, imagen)\n",
    "    shutil.move(ruta_origen, ruta_destino)\n",
    "\n",
    "print(\"Distribución completada.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1470e743",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Renombrado completado evitando duplicados.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "carpeta = 'img_test/Lote2'  # <-- cámbiala por la tuya\n",
    "\n",
    "for archivo in os.listdir(carpeta):\n",
    "    ruta_actual = os.path.join(carpeta, archivo)\n",
    "\n",
    "    if os.path.isfile(ruta_actual):\n",
    "        nombre_base, _ = os.path.splitext(archivo)\n",
    "        nuevo_nombre = nombre_base + '.jpg'\n",
    "        nueva_ruta = os.path.join(carpeta, nuevo_nombre)\n",
    "        \n",
    "        # Si ya existe un archivo con el nuevo nombre, añade un sufijo numérico\n",
    "        contador = 1\n",
    "        while os.path.exists(nueva_ruta):\n",
    "            nuevo_nombre = f\"{nombre_base}_{contador}.jpg\"\n",
    "            nueva_ruta = os.path.join(carpeta, nuevo_nombre)\n",
    "            contador += 1\n",
    "\n",
    "        os.rename(ruta_actual, nueva_ruta)\n",
    "\n",
    "print(\"Renombrado completado evitando duplicados.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a9ee06be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Renombrado completado.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Ruta con las imagenes\n",
    "carpeta = 'rx'\n",
    "extensiones_validas = ('.jpg', '.jpeg', '.png', '.bmp', '.gif', '.tif', '.tiff')\n",
    "\n",
    "# Obtener lista de imágenes y ordenarlas\n",
    "imagenes = sorted([f for f in os.listdir(carpeta) if f.lower().endswith(extensiones_validas)])\n",
    "\n",
    "# Renombrar cada imagen\n",
    "for i, nombre in enumerate(imagenes, start=1):\n",
    "    extension = os.path.splitext(nombre)[1]\n",
    "    nuevo_nombre = f'rx{i}{extension}'\n",
    "    ruta_vieja = os.path.join(carpeta, nombre)\n",
    "    ruta_nueva = os.path.join(carpeta, nuevo_nombre)\n",
    "    os.rename(ruta_vieja, ruta_nueva)\n",
    "\n",
    "print(\"Renombrado completado.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a6118b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/ultralytics/yolov5/zipball/master\" to C:\\Users\\josem/.cache\\torch\\hub\\master.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5  2025-6-20 Python-3.12.3 torch-2.7.1+cpu CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 157 layers, 7015519 parameters, 0 gradients, 15.8 GFLOPs\n",
      "Adding AutoShape... \n",
      "C:\\Users\\josem/.cache\\torch\\hub\\ultralytics_yolov5_master\\models\\common.py:906: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Umbral de confianza ajustado a: 0.85\n",
      "Imagen cargada correctamente: (1280, 2440, 3)\n",
      "\n",
      "=== RESULTADOS DE DETECCIÓN ===\n",
      "          xmin        ymin         xmax        ymax  confidence  class    name\n",
      "0  1137.677368  463.714294  1307.943481  780.272339    0.937926      1     inc\n",
      "1   994.286987  339.954651  1124.865356  613.205200    0.917207      0  canine\n",
      "2  1336.144165  352.465576  1449.814331  663.742249    0.908585      0  canine\n",
      "Línea media trazada en x=1222\n"
     ]
    }
   ],
   "source": [
    "# ======================================================================================================\n",
    "# Experimento 03: Medición de la proyección de los ángulos de los caninos sobre la línea media central\n",
    "# Se utilizan dos modelos\n",
    "# 1) Un modelo U-Net para segmentar la forma del canino (máscara)\n",
    "# 2) Un modelo YoloV5 para detectar la posición de los caninos e incisivos centrales\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "import math\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "from tooth_shape_model_unet import UNet\n",
    "from torchvision import transforms\n",
    "from PIL import Image \n",
    "\n",
    "\n",
    "# ======================================================================\n",
    "# Modelo U-Net para segmentación de caninos (obtener la forma del canino, para trazar la línea sobre él)\n",
    "\n",
    "IMG_HEIGHT = 256\n",
    "IMG_WIDTH = 256\n",
    "NUM_CLASSES = 3  # fondo, canino izquierdo, canino derecho\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "shape_unet = UNet(num_classes=NUM_CLASSES).to(device)\n",
    "shape_unet.load_state_dict(torch.load('models/tooth_shape_unet.pth', map_location=device))\n",
    "shape_unet.eval()\n",
    "\n",
    "infer_transform = transforms.Compose([\n",
    "    transforms.Resize((IMG_HEIGHT, IMG_WIDTH)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# ======================================================================\n",
    "# Modelo pre-entrenado (YoloV5) para la detección posicional de caninos e incisivos centrales\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = torch.hub.load(\n",
    "    'ultralytics/yolov5', \n",
    "    'custom',\n",
    "    path='models/tooth_detection.pt',\n",
    "    force_reload=True\n",
    ").to(device)\n",
    "\n",
    "# Umbral de confianza de detección posicional de caninos\n",
    "CONF_THRESHOLD = 0.85\n",
    "model.conf = CONF_THRESHOLD\n",
    "print(f\"Umbral de confianza ajustado a: {CONF_THRESHOLD}\")\n",
    "\n",
    "# =================================================================================================\n",
    "# Bloque principal\n",
    "\n",
    "# Path de la imagen de entrada\n",
    "# Sobre ésta imagen se ejecutará la detección de caninos y la segmentación de la forma del canino\n",
    "img_path = 'Muestra/rx1.jpg'\n",
    "if not os.path.exists(img_path):\n",
    "    print(f\"ERROR: La imagen no existe en {img_path}\")\n",
    "    exit()\n",
    "\n",
    "img = cv2.imread(img_path)\n",
    "if img is None:\n",
    "    print(f\"ERROR: No se pudo leer la imagen desde {img_path}\")\n",
    "    exit()\n",
    "\n",
    "print(f\"Imagen cargada correctamente: {img.shape}\")\n",
    "orig = img.copy()\n",
    "height, width = img.shape[:2]\n",
    "\n",
    "results = model(img)\n",
    "df = results.pandas().xyxy[0]  # xmin, ymin, xmax, ymax, confidence, class, name\n",
    "\n",
    "print(\"\\n=== RESULTADOS DE DETECCIÓN ===\")\n",
    "print(df)\n",
    "\n",
    "def calculate_line_intersection(line1_p1, line1_p2, line2_p1, line2_p2):\n",
    "    \"\"\"\n",
    "    Calcula el punto de intersección entre dos líneas definidas por dos puntos cada una.\n",
    "    Si las líneas son paralelas o no se intersectan dentro de los límites de la imagen, devuelve None.\n",
    "    \n",
    "    Args:\n",
    "        line1_p1, line1_p2: Puntos que definen la primera línea\n",
    "        line2_p1, line2_p2: Puntos que definen la segunda línea\n",
    "        \n",
    "    Returns:\n",
    "        tuple: Coordenadas (x, y) del punto de intersección o None si no hay intersección\n",
    "    \"\"\"\n",
    "    # Línea 1: (x1, y1) a (x2, y2)\n",
    "    x1, y1 = line1_p1\n",
    "    x2, y2 = line1_p2\n",
    "    \n",
    "    # Línea 2: (x3, y3) a (x4, y4)\n",
    "    x3, y3 = line2_p1\n",
    "    x4, y4 = line2_p2\n",
    "    \n",
    "    # Calcular denominador para verificar si las líneas son paralelas\n",
    "    denom = (y4 - y3) * (x2 - x1) - (x4 - x3) * (y2 - y1)\n",
    "    \n",
    "    if denom == 0:  # Líneas paralelas\n",
    "        return None\n",
    "    \n",
    "    # Calcular el punto de intersección\n",
    "    ua = ((x4 - x3) * (y1 - y3) - (y4 - y3) * (x1 - x3)) / denom\n",
    "    \n",
    "    # Punto de intersección\n",
    "    x = x1 + ua * (x2 - x1)\n",
    "    y = y1 + ua * (y2 - y1)\n",
    "    \n",
    "    return (int(x), int(y))\n",
    "\n",
    "def extend_line_to_boundaries(point1, point2, img_width, img_height, midline_x=None):\n",
    "    \"\"\"\n",
    "    Extiende una línea definida por dos puntos hasta los límites de la imagen o hasta intersectar con la línea media.\n",
    "    \n",
    "    Args:\n",
    "        point1 (tuple): Coordenadas (x, y) del primer punto.\n",
    "        point2 (tuple): Coordenadas (x, y) del segundo punto.\n",
    "        img_width (int): Ancho de la imagen.\n",
    "        img_height (int): Alto de la imagen.\n",
    "        midline_x (int, opcional): Coordenada x de la línea media. Si se proporciona, la línea se extenderá hasta esta línea.\n",
    "        \n",
    "    Returns:\n",
    "        tuple: Un par de tuplas con las coordenadas de los puntos extendidos (p1_extended, p2_extended).\n",
    "    \"\"\"\n",
    "    x1, y1 = point1\n",
    "    x2, y2 = point2\n",
    "    \n",
    "    # Si los puntos son iguales, no se puede definir una dirección\n",
    "    if x1 == x2 and y1 == y2:\n",
    "        return point1, point2\n",
    "    \n",
    "    # Calcular la dirección de la línea\n",
    "    dx = x2 - x1\n",
    "    dy = y2 - y1\n",
    "    \n",
    "    # Si la línea es vertical\n",
    "    if dx == 0:\n",
    "        # Extender hasta los bordes superior e inferior\n",
    "        return (x1, 0), (x1, img_height)\n",
    "    \n",
    "    # Calcular la pendiente y el intercepto\n",
    "    m = dy / dx\n",
    "    b = y1 - m * x1\n",
    "    \n",
    "    # Puntos extendidos\n",
    "    extended_points = []\n",
    "    \n",
    "    # Si hay una línea media definida, calcular la intersección con ella\n",
    "    if midline_x is not None:\n",
    "        # Calcular el punto de intersección con la línea media\n",
    "        y_intersect = m * midline_x + b\n",
    "        \n",
    "        # Verificar si la intersección está dentro de los límites de la imagen\n",
    "        if 0 <= y_intersect <= img_height:\n",
    "            # Determinar en qué lado de la línea media está el punto original\n",
    "            if (x1 < midline_x and x2 < midline_x) or (x1 > midline_x and x2 > midline_x):\n",
    "                # Ambos puntos están en el mismo lado de la línea media\n",
    "                # Extender hasta la línea media en una dirección\n",
    "                if x1 < midline_x:\n",
    "                    extended_points.append((midline_x, int(y_intersect)))\n",
    "                else:\n",
    "                    extended_points.append((midline_x, int(y_intersect)))\n",
    "            elif (x1 < midline_x and x2 > midline_x) or (x1 > midline_x and x2 < midline_x):\n",
    "                # No es necesario extender hasta la línea media\n",
    "                pass\n",
    "    \n",
    "    # Intersecciones con los bordes de la imagen\n",
    "    \n",
    "    # Intersección con y=0 (borde superior)\n",
    "    if abs(m) > 0.0001:  # No es una línea horizontal\n",
    "        x_top = (0 - b) / m\n",
    "        if 0 <= x_top <= img_width:\n",
    "            extended_points.append((int(x_top), 0))\n",
    "    \n",
    "    # Intersección con y=img_height (borde inferior)\n",
    "    if abs(m) > 0.0001:  # No es una línea horizontal\n",
    "        x_bottom = (img_height - b) / m\n",
    "        if 0 <= x_bottom <= img_width:\n",
    "            extended_points.append((int(x_bottom), img_height))\n",
    "    \n",
    "    # Intersección con x=0 (borde izquierdo)\n",
    "    y_left = b\n",
    "    if 0 <= y_left <= img_height:\n",
    "        extended_points.append((0, int(y_left)))\n",
    "    \n",
    "    # Intersección con x=img_width (borde derecho)\n",
    "    y_right = m * img_width + b\n",
    "    if 0 <= y_right <= img_height:\n",
    "        extended_points.append((img_width, int(y_right)))\n",
    "    \n",
    "    # Si no hay suficientes puntos de intersección, usar los puntos originales\n",
    "    if len(extended_points) < 2:\n",
    "        return point1, point2\n",
    "    \n",
    "    # Ordenar los puntos extendidos según su distancia desde el punto medio entre p1 y p2\n",
    "    midpoint = ((x1 + x2) / 2, (y1 + y2) / 2)\n",
    "    \n",
    "    # Si estamos del lado izquierdo de la línea media y queremos extender hacia la línea media\n",
    "    if midline_x is not None and (x1 < midline_x and x2 < midline_x):\n",
    "        # Encontrar el punto más cercano al borde y el punto más cercano a la línea media\n",
    "        points_sorted = sorted(extended_points, key=lambda p: p[0])  # Ordenar por coordenada x\n",
    "        return points_sorted[0], points_sorted[-1]  # El primero es el más a la izquierda, el último es el más a la derecha\n",
    "    \n",
    "    # Si estamos del lado derecho de la línea media y queremos extender hacia la línea media\n",
    "    elif midline_x is not None and (x1 > midline_x and x2 > midline_x):\n",
    "        # Encontrar el punto más cercano al borde y el punto más cercano a la línea media\n",
    "        points_sorted = sorted(extended_points, key=lambda p: p[0], reverse=True)  # Ordenar por coordenada x (reverso)\n",
    "        return points_sorted[0], points_sorted[-1]  # El primero es el más a la derecha, el último es el más a la izquierda\n",
    "    \n",
    "    # En otros casos, simplemente usar las dos intersecciones más alejadas entre sí\n",
    "    else:\n",
    "        # Calcular todas las combinaciones de distancias entre puntos\n",
    "        max_dist = 0\n",
    "        p1_ext, p2_ext = extended_points[0], extended_points[1]\n",
    "        \n",
    "        for i in range(len(extended_points)):\n",
    "            for j in range(i + 1, len(extended_points)):\n",
    "                dist = math.sqrt((extended_points[i][0] - extended_points[j][0])**2 + \n",
    "                                (extended_points[i][1] - extended_points[j][1])**2)\n",
    "                if dist > max_dist:\n",
    "                    max_dist = dist\n",
    "                    p1_ext, p2_ext = extended_points[i], extended_points[j]\n",
    "        \n",
    "        return p1_ext, p2_ext\n",
    "\n",
    "def get_center(detection):\n",
    "    xmin, ymin, xmax, ymax = map(int, [detection['xmin'], detection['ymin'], \n",
    "                                      detection['xmax'], detection['ymax']])\n",
    "    cx = (xmin + xmax) // 2\n",
    "    cy = (ymin + ymax) // 2\n",
    "    return (cx, cy)\n",
    "\n",
    "def get_corners(detection, side):\n",
    "    if side == 'izq':\n",
    "        return (int(detection['xmax']), int(detection['ymax'])), (int(detection['xmin']), int(detection['ymin']))\n",
    "    elif side == 'der':\n",
    "        return (int(detection['xmin']), int(detection['ymax'])), (int(detection['xmax']), int(detection['ymin']))\n",
    "    else:   \n",
    "        raise ValueError(\"Lado no válido. Debe ser 'izq' o 'der'.\")\n",
    "\n",
    "\n",
    "# Detecciones de incisivos y caninos\n",
    "incisor_detections = df[df['name'] == 'inc']\n",
    "canines  = df[df['name'] == 'canine']\n",
    "\n",
    "# Línea media desde incisivos\n",
    "inc_center = None\n",
    "if len(incisor_detections) > 0:\n",
    "    best_inc = incisor_detections.sort_values('confidence', ascending=False).iloc[0]\n",
    "    inc_center = get_center(best_inc)\n",
    "    # Dibujar línea media\n",
    "    cv2.line(orig, (inc_center[0], 0), (inc_center[0], height), (0, 255, 0), 2)\n",
    "    cv2.putText(orig, 'Línea media', (inc_center[0] + 10, 30),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "    print(f\"Línea media trazada en x={inc_center[0]}\")\n",
    "else:\n",
    "    print(\"No se detectaron incisivos; no se puede trazar la línea media.\")\n",
    "\n",
    "import math\n",
    "\n",
    "def segment_full_and_crop(orig_img, roi_coords):\n",
    "    # Segmenta toda la imagen y recorta ROI\n",
    "    img_rgb = cv2.cvtColor(orig_img, cv2.COLOR_BGR2RGB)\n",
    "    pil = Image.fromarray(img_rgb)\n",
    "    x = infer_transform(pil).unsqueeze(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        logits = shape_unet(x)\n",
    "        probs  = torch.softmax(logits, dim=1)[0]  # [3,H,W]\n",
    "\n",
    "    # si side=='left'\n",
    "    ch = probs[1] if side=='left' else probs[2]\n",
    "    heatmap = (ch.cpu().numpy() * 255).astype(np.uint8)\n",
    "    h, w = orig_img.shape[:2]\n",
    "    heatmap_full = cv2.resize(heatmap, (w, h), interpolation=cv2.INTER_LINEAR)\n",
    "    cv2.imwrite(f\"debug/heat_full_{side}.png\", heatmap_full)\n",
    "    chan = probs[1] if side=='left' else probs[2]\n",
    "    mask = (chan.cpu().numpy() > 0.03).astype(np.uint8) * 255\n",
    "    # redimensionar a full-res\n",
    "    h,w = orig_img.shape[:2]\n",
    "    mask_full = cv2.resize(mask,(w,h),interpolation=cv2.INTER_NEAREST)\n",
    "    # recortar\n",
    "    # x1,y1,x2,y2 = roi_coords\n",
    "    return mask_full\n",
    "\n",
    "\n",
    "def calculate_angle(line_p1, line_p2, vertical_line_x):\n",
    "    \"\"\"\n",
    "    Calcula el ángulo entre una línea definida por dos puntos y una línea vertical.\n",
    "    \n",
    "    Args:\n",
    "        line_p1 (tuple): Primer punto de la línea.\n",
    "        line_p2 (tuple): Segundo punto de la línea.\n",
    "        vertical_line_x (int): Coordenada x de la línea vertical.\n",
    "        \n",
    "    Returns:\n",
    "        float: Ángulo en grados entre las líneas.\n",
    "    \"\"\"\n",
    "    # Verificar que los puntos no sean iguales\n",
    "    if line_p1[0] == line_p2[0] and line_p1[1] == line_p2[1]:\n",
    "        return 0  # No se puede calcular el ángulo si los puntos son iguales\n",
    "    \n",
    "    # Vector de la línea\n",
    "    vector_line = (line_p2[0] - line_p1[0], line_p2[1] - line_p1[1])\n",
    "    \n",
    "    # Vector de la línea vertical (0, 1) normalizado\n",
    "    vector_vertical = (0, 1)\n",
    "    \n",
    "    # Calcular el ángulo entre los vectores usando el producto punto\n",
    "    # Normalizar los vectores\n",
    "    magnitude_line = math.sqrt(vector_line[0]**2 + vector_line[1]**2)\n",
    "    \n",
    "    if magnitude_line == 0:\n",
    "        return 0\n",
    "    \n",
    "    unit_vector_line = (vector_line[0] / magnitude_line, vector_line[1] / magnitude_line)\n",
    "    \n",
    "    # Producto punto de los vectores unitarios\n",
    "    dot_product = unit_vector_line[0] * vector_vertical[0] + unit_vector_line[1] * vector_vertical[1]\n",
    "    \n",
    "    # Asegurarse de que el producto punto esté en el rango [-1, 1]\n",
    "    dot_product = max(-1.0, min(1.0, dot_product))\n",
    "    \n",
    "    # Calcular el ángulo en radianes y convertirlo a grados\n",
    "    angle_rad = math.acos(dot_product)\n",
    "    angle_deg = math.degrees(angle_rad)\n",
    "    \n",
    "    # Determinar la dirección del ángulo (positivo o negativo)\n",
    "    # Si el punto p2 está a la derecha de la línea vertical, el ángulo es positivo\n",
    "    # Si está a la izquierda, el ángulo es negativo\n",
    "    direction = 1 if (line_p1[0] < vertical_line_x and line_p2[0] > vertical_line_x) or \\\n",
    "                    (line_p1[0] > vertical_line_x and line_p2[0] < vertical_line_x and line_p1[1] > line_p2[1]) else -1\n",
    "    \n",
    "    # Ajustar el ángulo según el cuadrante\n",
    "    if unit_vector_line[0] < 0:\n",
    "        angle_deg = 180 - angle_deg\n",
    "    \n",
    "    # Asegurarse de que el ángulo esté entre 0 y 180 grados\n",
    "    if angle_deg > 90:\n",
    "        angle_deg = 180 - angle_deg\n",
    "        \n",
    "    return angle_deg * direction\n",
    "\n",
    "def process_and_draw_canine(det, orig_img, side, inc_center_x=None):\n",
    "    coords = (int(det['xmin']), int(det['ymin']), int(det['xmax']), int(det['ymax']))\n",
    "    # Extraemos Cordenadas\n",
    "    x1, y1, x2, y2 = coords\n",
    "    roi = orig_img[coords[1]:coords[3], coords[0]:coords[2]]\n",
    "    # 1) Segmentar\n",
    "    mask_roi = segment_full_and_crop(roi, coords)\n",
    "    cv2.imwrite(f\"debug/mask_roi_{side}.png\", mask_roi)\n",
    "    # 2) Extraer contorno\n",
    "    cnts,_ = cv2.findContours(mask_roi,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\n",
    "    if not cnts: return orig_img\n",
    "    contour = max(cnts, key=cv2.contourArea).reshape(-1,2).astype(np.float32)\n",
    "    # 3) PCA\n",
    "    mean,vecs,_ = cv2.PCACompute2(contour, mean=None)\n",
    "    axis = vecs[0]\n",
    "    # 4) Extremos\n",
    "    dif = contour - mean\n",
    "    projs = dif.dot(axis.T)\n",
    "    p1 = list(contour[np.argmin(projs)].astype(int))\n",
    "    p2 = list(contour[np.argmax(projs)].astype(int))\n",
    "    if p1[1] > p2[1]: p1, p2 = p2, p1\n",
    "    \n",
    "    # Coordenadas punto 1\n",
    "    p1x = p1[0]\n",
    "    p1y = p1[1]\n",
    "    # Coordenadas punto 2\n",
    "    p2x = p2[0]\n",
    "    p2y = p2[1]\n",
    "    \n",
    "    if (side == \"izq\") and (p1x > p2x):\n",
    "        p1[1] = p2y\n",
    "        p2[1] = p1y\n",
    "    if (side == \"der\") and (p1x < p2x):\n",
    "        p1[1] = p2y\n",
    "        p2[1] = p1y\n",
    "        \n",
    "    # Ajustar a coords global\n",
    "    p1g = (p1[0]+coords[0], p1[1]+coords[1])\n",
    "    p2g = (p2[0]+coords[0], p2[1]+coords[1])\n",
    "    # 5) Dibujar\n",
    "    cv2.circle(orig_img, p1g, 4,(0,255,0),-1)\n",
    "    cv2.circle(orig_img, p2g, 4,(0,255,0),-1)\n",
    "\n",
    "    # Agregar punto (sacar despues)\n",
    "    cv2.putText(orig_img, 'p1', (p1g[0] + 10, p1g[1] - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "    cv2.putText(orig_img, 'p2', (p2g[0] + 10, p2g[1] - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "    \n",
    "    # Extender la línea hasta los límites de la imagen o hasta la línea media\n",
    "    h, w = orig_img.shape[:2]\n",
    "    midline_x = inc_center_x if inc_center_x is not None else None\n",
    "    \n",
    "    exp1, exp2 = extend_line_to_boundaries(p1g, p2g, w, h, midline_x)\n",
    "    \n",
    "    cv2.line(orig_img, exp1, exp2, (0,0,255), 2)\n",
    "    \n",
    "    # Para los angulos\n",
    "    # Coordenada central en X\n",
    "    center_x = (x1 + x2) // 2\n",
    "    # Coordenada para poner el texto justo debajo de la caja\n",
    "    text_y = y2 + 30\n",
    "\n",
    "    if midline_x is not None:\n",
    "        midline_top = (midline_x, 0)\n",
    "        midline_bottom = (midline_x, h)\n",
    "        intersection = calculate_line_intersection(exp1, exp2, midline_top, midline_bottom)\n",
    "        \n",
    "        if intersection:\n",
    "            cv2.circle(orig_img, intersection, 6, (255, 0, 255), -1)\n",
    "            angle = calculate_angle(exp1, exp2, midline_x)\n",
    "            angle_text = f\"Angulo: {abs(angle):.1f} Deg\"\n",
    "            cv2.putText(orig_img, angle_text, \n",
    "            (center_x - 50, text_y),  # desplazamos 50 px a la izquierda para centrar mejor el texto\n",
    "            cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 0, 255), 2)\n",
    "            \n",
    "            radius = 40\n",
    "            start_angle = 90\n",
    "            \n",
    "            if angle < 0:\n",
    "                end_angle = 90 - abs(angle)\n",
    "            else:\n",
    "                end_angle = 90 + abs(angle)\n",
    "            \n",
    "            cv2.ellipse(orig_img, intersection, (radius, radius), \n",
    "                        0, min(start_angle, end_angle), max(start_angle, end_angle), \n",
    "                        (255, 0, 255), 2)\n",
    "            \n",
    "            #cv2.putText(orig_img, \"Intersección\", \n",
    "             #          (intersection[0] + 10, intersection[1]), \n",
    "              #         cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 255), 2)\n",
    "    \n",
    "    return orig_img\n",
    "\n",
    "\n",
    "# Procesamiento de caninos usando el nuevo enfoque de análisis de forma\n",
    "for index, det in canines.iterrows():\n",
    "    center = get_center(det)\n",
    "    \n",
    "    # Determinar lado según x vs línea media\n",
    "    side = 'izq' if center[0] < inc_center[0] else 'der'\n",
    "    \n",
    "    # Dibujar bounding box del canino\n",
    "    x1, y1, x2, y2 = map(int, [det['xmin'], det['ymin'], det['xmax'], det['ymax']])\n",
    "    color = (255, 0, 0) if side == 'izq' else (0, 0, 255)\n",
    "    cv2.rectangle(orig, (x1, y1), (x2, y2), color, 2)\n",
    "\n",
    "    # Procesar y dibujar el canino con la línea extendida hasta la línea media\n",
    "    lined = process_and_draw_canine(det, orig, side, inc_center[0] if inc_center else None)\n",
    "    #cv2.imwrite('dental_shape_analysis_unet.jpg', lined)\n",
    "    \n",
    "    # Mostrar información de la detección\n",
    "    cv2.putText(orig, f\"Canino {side}: {det['confidence']:.2f}\", \n",
    "                (x1, y1-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "    \n",
    "    # Dibujar el centro del diente \n",
    "    cv2.circle(orig, center, 5, color, -1)\n",
    "\n",
    "# Dibujar todas las detecciones con centros\n",
    "def draw_box(det):\n",
    "    if det['name'] not in ['inc', 'canine']:\n",
    "        x1, y1, x2, y2 = map(int, [det['xmin'], det['ymin'], det['xmax'], det['ymax']])\n",
    "        color = (0, 255, 255)\n",
    "        cv2.rectangle(orig, (x1, y1), (x2, y2), color, 2)\n",
    "        cv2.putText(orig, f\"{det['name']}: {det['confidence']:.2f}\", \n",
    "                   (x1, y1-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "        c = get_center(det)\n",
    "        cv2.circle(orig, c, 5, color, -1)\n",
    "\n",
    "# Solo dibujamos las cajas para otras detecciones que no sean incisivos o caninos\n",
    "for _, det in df.iterrows():\n",
    "    if det['name'] not in ['inc', 'canine']:\n",
    "        draw_box(det)\n",
    "\n",
    "# Guardar y mostrar la imagen resultante\n",
    "cv2.imwrite('dental_shape_analysis.jpg', orig)\n",
    "cv2.destroyAllWindows()\n",
    "##"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
