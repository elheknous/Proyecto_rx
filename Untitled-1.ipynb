{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dfb550ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de formas cargadas: 0\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "num_samples should be a positive integer value, but got num_samples=0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 150\u001b[0m\n\u001b[0;32m    148\u001b[0m \u001b[38;5;66;03m# Creamos y entrenamos el modelo\u001b[39;00m\n\u001b[0;32m    149\u001b[0m model \u001b[38;5;241m=\u001b[39m DeepToothModel(n_landmarks\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m41\u001b[39m, latent_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m)\n\u001b[1;32m--> 150\u001b[0m losses \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontours\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m250\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    152\u001b[0m \u001b[38;5;66;03m# Visualizamos reconstrucciones\u001b[39;00m\n\u001b[0;32m    153\u001b[0m model\u001b[38;5;241m.\u001b[39mvisualize_reconstructions(contours)\n",
      "File \u001b[1;32mc:\\Users\\josem\\Desktop\\proyecto_dental\\tooth_shape_model_ml.py:205\u001b[0m, in \u001b[0;36mDeepToothModel.train\u001b[1;34m(self, contours, batch_size, epochs, lr)\u001b[0m\n\u001b[0;32m    203\u001b[0m \u001b[38;5;66;03m# Creamos el dataset y dataloader\u001b[39;00m\n\u001b[0;32m    204\u001b[0m dataset \u001b[38;5;241m=\u001b[39m ToothContourDataset(processed_contours)\n\u001b[1;32m--> 205\u001b[0m dataloader \u001b[38;5;241m=\u001b[39m \u001b[43mDataLoader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;66;03m# Configuramos el optimizador\u001b[39;00m\n\u001b[0;32m    208\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mlr)\n",
      "File \u001b[1;32mc:\\Users\\josem\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:385\u001b[0m, in \u001b[0;36mDataLoader.__init__\u001b[1;34m(self, dataset, batch_size, shuffle, sampler, batch_sampler, num_workers, collate_fn, pin_memory, drop_last, timeout, worker_init_fn, multiprocessing_context, generator, prefetch_factor, persistent_workers, pin_memory_device, in_order)\u001b[0m\n\u001b[0;32m    383\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# map-style\u001b[39;00m\n\u001b[0;32m    384\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m shuffle:\n\u001b[1;32m--> 385\u001b[0m         sampler \u001b[38;5;241m=\u001b[39m \u001b[43mRandomSampler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgenerator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgenerator\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m    386\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    387\u001b[0m         sampler \u001b[38;5;241m=\u001b[39m SequentialSampler(dataset)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\josem\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\data\\sampler.py:156\u001b[0m, in \u001b[0;36mRandomSampler.__init__\u001b[1;34m(self, data_source, replacement, num_samples, generator)\u001b[0m\n\u001b[0;32m    151\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m    152\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreplacement should be a boolean value, but got replacement=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreplacement\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    153\u001b[0m     )\n\u001b[0;32m    155\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_samples, \u001b[38;5;28mint\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_samples \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 156\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    157\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_samples should be a positive integer value, but got num_samples=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_samples\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    158\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: num_samples should be a positive integer value, but got num_samples=0"
     ]
    }
   ],
   "source": [
    "# ===================================================================================================\n",
    "# Experimento de prueba para el modelo de segmentación de caninos en base a un ASM\n",
    "# ESTE MODELO ESTÁ OBSOLETO Y NO LOGRÓ UNA SEGMENTACIÓN ADECUADA\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from pathlib import Path\n",
    "import json\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.interpolate import splprep, splev\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "from tooth_shape_model import ToothShapeModel\n",
    "from tooth_shape_model_ml import ToothContourDataset, DeepToothModel\n",
    "\n",
    "\n",
    "def signed_area(points):\n",
    "    \"\"\"\n",
    "    Calcula el área firmada de un polígono.\n",
    "    >0 → CCW,  <0 → CW\n",
    "    \"\"\"\n",
    "    x = points[:,0]\n",
    "    y = points[:,1]\n",
    "    # fórmula del shoelace:\n",
    "    return 0.5 * np.sum(x[:-1]*y[1:] - x[1:]*y[:-1]) + \\\n",
    "           0.5 * (x[-1]*y[0] - x[0]*y[-1])\n",
    "\n",
    "def ensure_clockwise(points):\n",
    "    \"\"\"\n",
    "    Si el polígono está en sentido CCW, lo invierte.\n",
    "    \"\"\"\n",
    "    if signed_area(points) > 0:\n",
    "        return points[::-1]\n",
    "    return points\n",
    "\n",
    "def extract_landmarks_from_contour(contour, n_landmarks=40):\n",
    "    \"\"\"\n",
    "    Convierte un contorno en un conjunto equidistante de landmarks\n",
    "    \n",
    "    Args:\n",
    "        contour: Contorno de OpenCV o array de puntos (n_points, 2)\n",
    "        n_landmarks: Número deseado de landmarks\n",
    "        \n",
    "    Returns:\n",
    "        landmarks: Array de landmarks equidistantes\n",
    "    \"\"\"\n",
    "    # Asegurar que contour sea un array numpy\n",
    "    if isinstance(contour, np.ndarray):\n",
    "        if len(contour.shape) == 3 and contour.shape[1] == 1:\n",
    "            # Formato de contorno OpenCV\n",
    "            points = contour.squeeze()\n",
    "        else:\n",
    "            # Ya es un array de puntos\n",
    "            points = contour\n",
    "    else:\n",
    "        raise ValueError(\"El contorno debe ser un array numpy\")\n",
    "    \n",
    "    points = ensure_clockwise(points)  # Asegurar sentido horario\n",
    "    \n",
    "    # Si hay menos puntos que landmarks requeridos, usar interpolación\n",
    "    if len(points) < n_landmarks:\n",
    "        tck, u = splprep([points[:, 0], points[:, 1]], s=0, per=True)\n",
    "        u_new = np.linspace(0, 1, n_landmarks)\n",
    "        x_new, y_new = splev(u_new, tck)\n",
    "        landmarks = np.column_stack([x_new, y_new])\n",
    "        return landmarks\n",
    "    \n",
    "    # Calcular longitud total del contorno\n",
    "    total_length = 0\n",
    "    for i in range(len(points)):\n",
    "        next_idx = (i + 1) % len(points)\n",
    "        segment_length = np.linalg.norm(points[i] - points[next_idx])\n",
    "        total_length += segment_length\n",
    "    \n",
    "    # Distribuir landmarks equidistantemente\n",
    "    landmarks = []\n",
    "    target_length = total_length / n_landmarks\n",
    "    current_length = 0\n",
    "    start_idx = 0\n",
    "    \n",
    "    for i in range(n_landmarks):\n",
    "        landmarks.append(points[start_idx].copy())\n",
    "        \n",
    "        # Avanzar hasta la siguiente posición de landmark\n",
    "        while current_length < target_length:\n",
    "            next_idx = (start_idx + 1) % len(points)\n",
    "            segment_length = np.linalg.norm(points[start_idx] - points[next_idx])\n",
    "            \n",
    "            if current_length + segment_length >= target_length:\n",
    "                # Interpolar para encontrar el punto exacto\n",
    "                excess = current_length + segment_length - target_length\n",
    "                ratio = excess / segment_length\n",
    "                start_idx = next_idx\n",
    "                if ratio > 0:\n",
    "                    prev_idx = (start_idx - 1) % len(points)\n",
    "                    start_point = points[prev_idx] + (1 - ratio) * (points[start_idx] - points[prev_idx])\n",
    "                    points[start_idx] = start_point\n",
    "                \n",
    "                current_length = 0\n",
    "                break\n",
    "            else:\n",
    "                current_length += segment_length\n",
    "                start_idx = next_idx\n",
    "    \n",
    "    return np.array(landmarks)\n",
    "\n",
    "\n",
    "# Funciones para cargar datos anotados desde diferentes formatos\n",
    "def load_shapes_from_labelme_dir(dataset_dir, n_landmarks=40):\n",
    "    shapes = []\n",
    "    dataset_dir = Path(dataset_dir)\n",
    "    for json_path in dataset_dir.glob(\"*.json\"):\n",
    "        with open(json_path, 'r') as f:\n",
    "            data = json.load(f)\n",
    "        for shape_info in data.get('shapes', []):\n",
    "            if shape_info['shape_type'] != 'polygon': \n",
    "                continue\n",
    "            points = np.array(shape_info['points'], dtype=float)\n",
    "            side   = shape_info.get('description', 'left')  # o tu atributo personalizado\n",
    "            # normalizamos el lado:\n",
    "            points = maybe_flip(points, side)\n",
    "            points[:,1] *= -1\n",
    "            # extraemos landmarks equidistantes:\n",
    "            lm = extract_landmarks_from_contour(points, n_landmarks)\n",
    "            shapes.append(lm)\n",
    "    return shapes\n",
    "\n",
    "def maybe_flip(points, side):\n",
    "    \"\"\"\n",
    "    Refleja horizontalmente si es un canino derecho, \n",
    "    para homogenizar todas las formas como 'izquierdas'.\n",
    "    \"\"\"\n",
    "    if side == 'right':\n",
    "        cx = np.mean(points[:,0])\n",
    "        points[:,0] = 2*cx - points[:,0]\n",
    "    return points\n",
    "\n",
    "\n",
    "# 1) Carga todas las formas\n",
    "shapes = load_shapes_from_labelme_dir(\"../data/asm-train/\", n_landmarks=41)\n",
    "print(f\"Total de formas cargadas: {len(shapes)}\")\n",
    "\n",
    "contours = shapes.copy()\n",
    "\n",
    "# Creamos y entrenamos el modelo\n",
    "model = DeepToothModel(n_landmarks=41, latent_dim=8)\n",
    "losses = model.train(contours, epochs=250, batch_size=4)\n",
    "    \n",
    "# Visualizamos reconstrucciones\n",
    "model.visualize_reconstructions(contours)\n",
    "    \n",
    "# Visualizamos el espacio latente\n",
    "model.visualize_latent_space(contours)\n",
    "\n",
    "model.save_model(\"../models/canine_deep_model.h5\")\n",
    "    \n",
    "# Visualizamos modos de variación\n",
    "model.visualize_mode_variations()\n",
    "    \n",
    "# Generamos nuevas formas\n",
    "variations = model.generate_variations(n_variations=5)\n",
    "    \n",
    "# Visualizamos las variaciones generadas\n",
    "plt.figure(figsize=(15, 3))\n",
    "for i, var in enumerate(variations):\n",
    "    plt.subplot(1, 5, i+1)\n",
    "    plt.plot(var[:, 0], var[:, 1], 'g-o', markersize=4)\n",
    "    plt.title(f\"Variación {i+1}\")\n",
    "    plt.axis('equal')\n",
    "    plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "mean_shape = model.get_mean_shape(contours)\n",
    "\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.plot(mean_shape[:, 0], mean_shape[:, 1], 'b-o', markersize=4, label='Forma Media')\n",
    "plt.title(\"Forma Media del Canino Aprendida\")\n",
    "plt.axis('equal')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "model.save_model(\"../models/canine_deep_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d623a687",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\Admn/.cache\\torch\\hub\\ultralytics_yolov5_master\n",
      "YOLOv5  2025-5-1 Python-3.10.11 torch-2.0.1+cu117 CUDA:0 (NVIDIA GeForce GTX 1660 SUPER, 6144MiB)\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 157 layers, 7015519 parameters, 0 gradients, 15.8 GFLOPs\n",
      "Adding AutoShape... \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROIs para 02 REYES BUSTOS PASCALE 09-10-10: {'left': {'xmin': 992, 'ymin': 361, 'xmax': 1122, 'ymax': 571}, 'right': {'xmin': 1344, 'ymin': 385, 'xmax': 1475, 'ymax': 580}}\n",
      "Guardado left: 02 REYES BUSTOS PASCALE 09-10-10_izq.jpg, 02 REYES BUSTOS PASCALE 09-10-10_izq.png\n",
      "Guardado right: 02 REYES BUSTOS PASCALE 09-10-10_der.jpg, 02 REYES BUSTOS PASCALE 09-10-10_der.png\n",
      "ROIs para ABARZUA VIDAL MARTIN (2): {'left': {'xmin': 994, 'ymin': 339, 'xmax': 1124, 'ymax': 613}, 'right': {'xmin': 1336, 'ymin': 352, 'xmax': 1449, 'ymax': 663}}\n",
      "Guardado left: ABARZUA VIDAL MARTIN (2)_izq.jpg, ABARZUA VIDAL MARTIN (2)_izq.png\n",
      "Guardado right: ABARZUA VIDAL MARTIN (2)_der.jpg, ABARZUA VIDAL MARTIN (2)_der.png\n",
      "ROIs para ACUÑA FULLER BENJAMIN 22-05-10  1: {'left': {'xmin': 981, 'ymin': 334, 'xmax': 1137, 'ymax': 591}, 'right': {'xmin': 1369, 'ymin': 337, 'xmax': 1499, 'ymax': 584}}\n",
      "Guardado left: ACUÑA FULLER BENJAMIN 22-05-10  1_izq.jpg, ACUÑA FULLER BENJAMIN 22-05-10  1_izq.png\n",
      "Guardado right: ACUÑA FULLER BENJAMIN 22-05-10  1_der.jpg, ACUÑA FULLER BENJAMIN 22-05-10  1_der.png\n",
      "ROIs para ALARCON CALLUMAN CRISTIAN  (1): {'left': {'xmin': 972, 'ymin': 416, 'xmax': 1147, 'ymax': 652}, 'right': {'xmin': 1387, 'ymin': 438, 'xmax': 1553, 'ymax': 638}}\n",
      "Guardado left: ALARCON CALLUMAN CRISTIAN  (1)_izq.jpg, ALARCON CALLUMAN CRISTIAN  (1)_izq.png\n",
      "Guardado right: ALARCON CALLUMAN CRISTIAN  (1)_der.jpg, ALARCON CALLUMAN CRISTIAN  (1)_der.png\n",
      "ROIs para ALBORNOZ VILUGRON FRANCISCA 07-02-08_1: {'left': {'xmin': 1090, 'ymin': 288, 'xmax': 1272, 'ymax': 525}, 'right': {'xmin': 1437, 'ymin': 325, 'xmax': 1541, 'ymax': 631}}\n",
      "Guardado left: ALBORNOZ VILUGRON FRANCISCA 07-02-08_1_izq.jpg, ALBORNOZ VILUGRON FRANCISCA 07-02-08_1_izq.png\n",
      "Guardado right: ALBORNOZ VILUGRON FRANCISCA 07-02-08_1_der.jpg, ALBORNOZ VILUGRON FRANCISCA 07-02-08_1_der.png\n",
      "ROIs para ARIAS GUAJARDO AGUSTINA: {'left': {'xmin': 934, 'ymin': 354, 'xmax': 1058, 'ymax': 590}, 'right': {'xmin': 1256, 'ymin': 362, 'xmax': 1370, 'ymax': 591}}\n",
      "Guardado left: ARIAS GUAJARDO AGUSTINA_izq.jpg, ARIAS GUAJARDO AGUSTINA_izq.png\n",
      "Guardado right: ARIAS GUAJARDO AGUSTINA_der.jpg, ARIAS GUAJARDO AGUSTINA_der.png\n",
      "ROIs para ARIAS REYES LAURA (2): {'left': {'xmin': 1012, 'ymin': 375, 'xmax': 1130, 'ymax': 594}, 'right': {'xmin': 1259, 'ymin': 378, 'xmax': 1430, 'ymax': 587}}\n",
      "Guardado left: ARIAS REYES LAURA (2)_izq.jpg, ARIAS REYES LAURA (2)_izq.png\n",
      "Guardado right: ARIAS REYES LAURA (2)_der.jpg, ARIAS REYES LAURA (2)_der.png\n",
      "ROIs para AROCA MORA CAMILA: {'left': {'xmin': 1055, 'ymin': 320, 'xmax': 1180, 'ymax': 557}, 'right': {'xmin': 1361, 'ymin': 330, 'xmax': 1479, 'ymax': 561}}\n",
      "Guardado left: AROCA MORA CAMILA_izq.jpg, AROCA MORA CAMILA_izq.png\n",
      "Guardado right: AROCA MORA CAMILA_der.jpg, AROCA MORA CAMILA_der.png\n",
      "ROIs para BARRA ITURRA PAZ 01-12-12: {'left': {'xmin': 985, 'ymin': 396, 'xmax': 1122, 'ymax': 608}, 'right': {'xmin': 1319, 'ymin': 381, 'xmax': 1450, 'ymax': 602}}\n",
      "Guardado left: BARRA ITURRA PAZ 01-12-12_izq.jpg, BARRA ITURRA PAZ 01-12-12_izq.png\n",
      "Guardado right: BARRA ITURRA PAZ 01-12-12_der.jpg, BARRA ITURRA PAZ 01-12-12_der.png\n",
      "ROIs para BARRA ITURRA PAZ 01-12-12_1: {'left': {'xmin': 925, 'ymin': 390, 'xmax': 1038, 'ymax': 578}, 'right': {'xmin': 1265, 'ymin': 379, 'xmax': 1385, 'ymax': 570}}\n",
      "Guardado left: BARRA ITURRA PAZ 01-12-12_1_izq.jpg, BARRA ITURRA PAZ 01-12-12_1_izq.png\n",
      "Guardado right: BARRA ITURRA PAZ 01-12-12_1_der.jpg, BARRA ITURRA PAZ 01-12-12_1_der.png\n",
      "ROIs para BECERRA FLORES JUVENAL 13-09-03 (1): {'left': {'xmin': 997, 'ymin': 318, 'xmax': 1152, 'ymax': 608}, 'right': {'xmin': 1323, 'ymin': 321, 'xmax': 1454, 'ymax': 604}}\n",
      "Guardado left: BECERRA FLORES JUVENAL 13-09-03 (1)_izq.jpg, BECERRA FLORES JUVENAL 13-09-03 (1)_izq.png\n",
      "Guardado right: BECERRA FLORES JUVENAL 13-09-03 (1)_der.jpg, BECERRA FLORES JUVENAL 13-09-03 (1)_der.png\n",
      "ROIs para BELLO BENAVIDES CRISTOFER: {'left': {'xmin': 1043, 'ymin': 236, 'xmax': 1173, 'ymax': 529}, 'right': {'xmin': 1322, 'ymin': 266, 'xmax': 1469, 'ymax': 545}}\n",
      "Guardado left: BELLO BENAVIDES CRISTOFER_izq.jpg, BELLO BENAVIDES CRISTOFER_izq.png\n",
      "Guardado right: BELLO BENAVIDES CRISTOFER_der.jpg, BELLO BENAVIDES CRISTOFER_der.png\n",
      "ROIs para BELLO BENAVIDES CRISTOPFER_1: {'left': {'xmin': 1012, 'ymin': 269, 'xmax': 1145, 'ymax': 570}, 'right': {'xmin': 1313, 'ymin': 268, 'xmax': 1456, 'ymax': 572}}\n",
      "Guardado left: BELLO BENAVIDES CRISTOPFER_1_izq.jpg, BELLO BENAVIDES CRISTOPFER_1_izq.png\n",
      "Guardado right: BELLO BENAVIDES CRISTOPFER_1_der.jpg, BELLO BENAVIDES CRISTOPFER_1_der.png\n",
      "ROIs para BELLO BENAVIDES CRISTOPHER 25-07-10: {'left': {'xmin': 987, 'ymin': 296, 'xmax': 1121, 'ymax': 555}, 'right': {'xmin': 1305, 'ymin': 287, 'xmax': 1452, 'ymax': 540}}\n",
      "Guardado left: BELLO BENAVIDES CRISTOPHER 25-07-10_izq.jpg, BELLO BENAVIDES CRISTOPHER 25-07-10_izq.png\n",
      "Guardado right: BELLO BENAVIDES CRISTOPHER 25-07-10_der.jpg, BELLO BENAVIDES CRISTOPHER 25-07-10_der.png\n",
      "ROIs para BELLO BENAVIDES CRISTOPHER: {'left': {'xmin': 989, 'ymin': 317, 'xmax': 1116, 'ymax': 528}, 'right': {'xmin': 1320, 'ymin': 311, 'xmax': 1464, 'ymax': 540}}\n",
      "Guardado left: BELLO BENAVIDES CRISTOPHER_izq.jpg, BELLO BENAVIDES CRISTOPHER_izq.png\n",
      "Guardado right: BELLO BENAVIDES CRISTOPHER_der.jpg, BELLO BENAVIDES CRISTOPHER_der.png\n",
      "ROIs para BELLO NORAMBUENA ROCIO 29-12-2007 (1): {'left': {'xmin': 982, 'ymin': 328, 'xmax': 1117, 'ymax': 612}, 'right': {'xmin': 1317, 'ymin': 342, 'xmax': 1435, 'ymax': 618}}\n",
      "Guardado left: BELLO NORAMBUENA ROCIO 29-12-2007 (1)_izq.jpg, BELLO NORAMBUENA ROCIO 29-12-2007 (1)_izq.png\n",
      "Guardado right: BELLO NORAMBUENA ROCIO 29-12-2007 (1)_der.jpg, BELLO NORAMBUENA ROCIO 29-12-2007 (1)_der.png\n",
      "ROIs para BELTRAN MILA SOFIA  (1): {'left': {'xmin': 1006, 'ymin': 310, 'xmax': 1138, 'ymax': 553}, 'right': {'xmin': 1303, 'ymin': 326, 'xmax': 1433, 'ymax': 584}}\n",
      "Guardado left: BELTRAN MILA SOFIA  (1)_izq.jpg, BELTRAN MILA SOFIA  (1)_izq.png\n",
      "Guardado right: BELTRAN MILA SOFIA  (1)_der.jpg, BELTRAN MILA SOFIA  (1)_der.png\n",
      "ROIs para BELTRAN ROJAS ANALIE_1: {'left': {'xmin': 1007, 'ymin': 351, 'xmax': 1140, 'ymax': 600}, 'right': {'xmin': 1294, 'ymin': 351, 'xmax': 1460, 'ymax': 593}}\n",
      "Guardado left: BELTRAN ROJAS ANALIE_1_izq.jpg, BELTRAN ROJAS ANALIE_1_izq.png\n",
      "Guardado right: BELTRAN ROJAS ANALIE_1_der.jpg, BELTRAN ROJAS ANALIE_1_der.png\n",
      "ROIs para BENAVIDES LIZAMA JAVIER 05-09-09 (1): {'left': {'xmin': 987, 'ymin': 347, 'xmax': 1104, 'ymax': 597}, 'right': {'xmin': 1327, 'ymin': 334, 'xmax': 1466, 'ymax': 581}}\n",
      "Guardado left: BENAVIDES LIZAMA JAVIER 05-09-09 (1)_izq.jpg, BENAVIDES LIZAMA JAVIER 05-09-09 (1)_izq.png\n",
      "Guardado right: BENAVIDES LIZAMA JAVIER 05-09-09 (1)_der.jpg, BENAVIDES LIZAMA JAVIER 05-09-09 (1)_der.png\n",
      "ROIs para BLANCK ULLOA EVOLLETTE (2): {'left': {'xmin': 971, 'ymin': 363, 'xmax': 1075, 'ymax': 600}, 'right': {'xmin': 1272, 'ymin': 364, 'xmax': 1377, 'ymax': 585}}\n",
      "Guardado left: BLANCK ULLOA EVOLLETTE (2)_izq.jpg, BLANCK ULLOA EVOLLETTE (2)_izq.png\n",
      "Guardado right: BLANCK ULLOA EVOLLETTE (2)_der.jpg, BLANCK ULLOA EVOLLETTE (2)_der.png\n",
      "ROIs para BLUAS GUZMAN EDISON 17-02-09 (1): {'left': {'xmin': 997, 'ymin': 364, 'xmax': 1156, 'ymax': 587}, 'right': {'xmin': 1384, 'ymin': 393, 'xmax': 1532, 'ymax': 615}}\n",
      "Guardado left: BLUAS GUZMAN EDISON 17-02-09 (1)_izq.jpg, BLUAS GUZMAN EDISON 17-02-09 (1)_izq.png\n",
      "Guardado right: BLUAS GUZMAN EDISON 17-02-09 (1)_der.jpg, BLUAS GUZMAN EDISON 17-02-09 (1)_der.png\n",
      "ROIs para BRAVO LEON FRANCISCO 18-06-10: {'left': {'xmin': 973, 'ymin': 327, 'xmax': 1122, 'ymax': 541}, 'right': {'xmin': 1321, 'ymin': 366, 'xmax': 1467, 'ymax': 579}}\n",
      "Guardado left: BRAVO LEON FRANCISCO 18-06-10_izq.jpg, BRAVO LEON FRANCISCO 18-06-10_izq.png\n",
      "Guardado right: BRAVO LEON FRANCISCO 18-06-10_der.jpg, BRAVO LEON FRANCISCO 18-06-10_der.png\n",
      "ROIs para BRAVO PACHECO LIA  (2): {'left': {'xmin': 1026, 'ymin': 352, 'xmax': 1153, 'ymax': 621}, 'right': {'xmin': 1379, 'ymin': 363, 'xmax': 1476, 'ymax': 615}}\n",
      "Guardado left: BRAVO PACHECO LIA  (2)_izq.jpg, BRAVO PACHECO LIA  (2)_izq.png\n",
      "Guardado right: BRAVO PACHECO LIA  (2)_der.jpg, BRAVO PACHECO LIA  (2)_der.png\n",
      "ROIs para BRIONES BRAVO PASCAL  (2): {'left': {'xmin': 911, 'ymin': 288, 'xmax': 1025, 'ymax': 510}, 'right': {'xmin': 1201, 'ymin': 296, 'xmax': 1343, 'ymax': 510}}\n",
      "Guardado left: BRIONES BRAVO PASCAL  (2)_izq.jpg, BRIONES BRAVO PASCAL  (2)_izq.png\n",
      "Guardado right: BRIONES BRAVO PASCAL  (2)_der.jpg, BRIONES BRAVO PASCAL  (2)_der.png\n",
      "ROIs para BUSTOS FARIAS VICTOR 04-07-07 (1): {'left': {'xmin': 1092, 'ymin': 380, 'xmax': 1222, 'ymax': 653}, 'right': {'xmin': 1489, 'ymin': 339, 'xmax': 1613, 'ymax': 644}}\n",
      "Guardado left: BUSTOS FARIAS VICTOR 04-07-07 (1)_izq.jpg, BUSTOS FARIAS VICTOR 04-07-07 (1)_izq.png\n",
      "Guardado right: BUSTOS FARIAS VICTOR 04-07-07 (1)_der.jpg, BUSTOS FARIAS VICTOR 04-07-07 (1)_der.png\n",
      "ROIs para BUSTOS RODRIGUEZ ISABELLA 24-11-12 (1): {'left': {'xmin': 1032, 'ymin': 334, 'xmax': 1161, 'ymax': 599}, 'right': {'xmin': 1360, 'ymin': 312, 'xmax': 1471, 'ymax': 561}}\n",
      "Guardado left: BUSTOS RODRIGUEZ ISABELLA 24-11-12 (1)_izq.jpg, BUSTOS RODRIGUEZ ISABELLA 24-11-12 (1)_izq.png\n",
      "Guardado right: BUSTOS RODRIGUEZ ISABELLA 24-11-12 (1)_der.jpg, BUSTOS RODRIGUEZ ISABELLA 24-11-12 (1)_der.png\n",
      "ROIs para CABEZAS FUENTES TOMAS 25-05-07: {'left': {'xmin': 970, 'ymin': 341, 'xmax': 1126, 'ymax': 628}, 'right': {'xmin': 1330, 'ymin': 345, 'xmax': 1473, 'ymax': 639}}\n",
      "Guardado left: CABEZAS FUENTES TOMAS 25-05-07_izq.jpg, CABEZAS FUENTES TOMAS 25-05-07_izq.png\n",
      "Guardado right: CABEZAS FUENTES TOMAS 25-05-07_der.jpg, CABEZAS FUENTES TOMAS 25-05-07_der.png\n",
      "ROIs para CABRERA GUERRERO AMANDA: {'right': {'xmin': 1307, 'ymin': 337, 'xmax': 1451, 'ymax': 587}}\n",
      "Guardado right: CABRERA GUERRERO AMANDA_der.jpg, CABRERA GUERRERO AMANDA_der.png\n",
      "ROIs para CABRERA GUERRERO JOSEFINA_1: {'left': {'xmin': 987, 'ymin': 347, 'xmax': 1132, 'ymax': 560}, 'right': {'xmin': 1349, 'ymin': 350, 'xmax': 1485, 'ymax': 579}}\n",
      "Guardado left: CABRERA GUERRERO JOSEFINA_1_izq.jpg, CABRERA GUERRERO JOSEFINA_1_izq.png\n",
      "Guardado right: CABRERA GUERRERO JOSEFINA_1_der.jpg, CABRERA GUERRERO JOSEFINA_1_der.png\n",
      "ROIs para CALFIO VILLAGRAN JUAN PABLO (2): {'left': {'xmin': 1095, 'ymin': 359, 'xmax': 1243, 'ymax': 620}, 'right': {'xmin': 1459, 'ymin': 353, 'xmax': 1585, 'ymax': 611}}\n",
      "Guardado left: CALFIO VILLAGRAN JUAN PABLO (2)_izq.jpg, CALFIO VILLAGRAN JUAN PABLO (2)_izq.png\n",
      "Guardado right: CALFIO VILLAGRAN JUAN PABLO (2)_der.jpg, CALFIO VILLAGRAN JUAN PABLO (2)_der.png\n",
      "ROIs para CAMPOS MANRIQUEZ TAMARA: {'left': {'xmin': 1038, 'ymin': 344, 'xmax': 1155, 'ymax': 607}, 'right': {'xmin': 1275, 'ymin': 343, 'xmax': 1467, 'ymax': 548}}\n",
      "Guardado left: CAMPOS MANRIQUEZ TAMARA_izq.jpg, CAMPOS MANRIQUEZ TAMARA_izq.png\n",
      "Guardado right: CAMPOS MANRIQUEZ TAMARA_der.jpg, CAMPOS MANRIQUEZ TAMARA_der.png\n",
      "ROIs para CAMPOS PAILLAN ADOLFO 20-12-08: {'left': {'xmin': 930, 'ymin': 340, 'xmax': 1108, 'ymax': 544}, 'right': {'xmin': 1312, 'ymin': 327, 'xmax': 1471, 'ymax': 587}}\n",
      "Guardado left: CAMPOS PAILLAN ADOLFO 20-12-08_izq.jpg, CAMPOS PAILLAN ADOLFO 20-12-08_izq.png\n",
      "Guardado right: CAMPOS PAILLAN ADOLFO 20-12-08_der.jpg, CAMPOS PAILLAN ADOLFO 20-12-08_der.png\n",
      "ROIs para CAMPOS PAILLAN ADOLFO 2012-08 (1): {'left': {'xmin': 958, 'ymin': 303, 'xmax': 1115, 'ymax': 556}, 'right': {'xmin': 1310, 'ymin': 312, 'xmax': 1438, 'ymax': 604}}\n",
      "Guardado left: CAMPOS PAILLAN ADOLFO 2012-08 (1)_izq.jpg, CAMPOS PAILLAN ADOLFO 2012-08 (1)_izq.png\n",
      "Guardado right: CAMPOS PAILLAN ADOLFO 2012-08 (1)_der.jpg, CAMPOS PAILLAN ADOLFO 2012-08 (1)_der.png\n",
      "ROIs para CAMPOS PAILLAN ADOLFO: {'left': {'xmin': 945, 'ymin': 307, 'xmax': 1129, 'ymax': 539}, 'right': {'xmin': 1320, 'ymin': 322, 'xmax': 1463, 'ymax': 592}}\n",
      "Guardado left: CAMPOS PAILLAN ADOLFO_izq.jpg, CAMPOS PAILLAN ADOLFO_izq.png\n",
      "Guardado right: CAMPOS PAILLAN ADOLFO_der.jpg, CAMPOS PAILLAN ADOLFO_der.png\n",
      "ROIs para CASTILLO LAZCANO JOSEFA  (2): {'left': {'xmin': 1009, 'ymin': 352, 'xmax': 1118, 'ymax': 594}, 'right': {'xmin': 1299, 'ymin': 330, 'xmax': 1413, 'ymax': 565}}\n",
      "Guardado left: CASTILLO LAZCANO JOSEFA  (2)_izq.jpg, CASTILLO LAZCANO JOSEFA  (2)_izq.png\n",
      "Guardado right: CASTILLO LAZCANO JOSEFA  (2)_der.jpg, CASTILLO LAZCANO JOSEFA  (2)_der.png\n",
      "ROIs para CASTRO PILQUIMAN LUCIANA 20-01-11: {'left': {'xmin': 1031, 'ymin': 347, 'xmax': 1157, 'ymax': 622}, 'right': {'xmin': 1348, 'ymin': 380, 'xmax': 1498, 'ymax': 615}}\n",
      "Guardado left: CASTRO PILQUIMAN LUCIANA 20-01-11_izq.jpg, CASTRO PILQUIMAN LUCIANA 20-01-11_izq.png\n",
      "Guardado right: CASTRO PILQUIMAN LUCIANA 20-01-11_der.jpg, CASTRO PILQUIMAN LUCIANA 20-01-11_der.png\n",
      "ROIs para CATRILAF PAREDES JUAN JOSE: {'left': {'xmin': 997, 'ymin': 386, 'xmax': 1118, 'ymax': 611}, 'right': {'xmin': 1329, 'ymin': 373, 'xmax': 1452, 'ymax': 605}}\n",
      "Guardado left: CATRILAF PAREDES JUAN JOSE_izq.jpg, CATRILAF PAREDES JUAN JOSE_izq.png\n",
      "Guardado right: CATRILAF PAREDES JUAN JOSE_der.jpg, CATRILAF PAREDES JUAN JOSE_der.png\n",
      "ROIs para CATRILAF PAREDES JUAN JOSE_1: {'left': {'xmin': 1043, 'ymin': 387, 'xmax': 1166, 'ymax': 619}, 'right': {'xmin': 1369, 'ymin': 378, 'xmax': 1480, 'ymax': 636}}\n",
      "Guardado left: CATRILAF PAREDES JUAN JOSE_1_izq.jpg, CATRILAF PAREDES JUAN JOSE_1_izq.png\n",
      "Guardado right: CATRILAF PAREDES JUAN JOSE_1_der.jpg, CATRILAF PAREDES JUAN JOSE_1_der.png\n",
      "ROIs para CAYUL BLANCO ALEX24-11-10 (2): {'left': {'xmin': 1102, 'ymin': 313, 'xmax': 1244, 'ymax': 551}, 'right': {'xmin': 1450, 'ymin': 303, 'xmax': 1602, 'ymax': 521}}\n",
      "Guardado left: CAYUL BLANCO ALEX24-11-10 (2)_izq.jpg, CAYUL BLANCO ALEX24-11-10 (2)_izq.png\n",
      "Guardado right: CAYUL BLANCO ALEX24-11-10 (2)_der.jpg, CAYUL BLANCO ALEX24-11-10 (2)_der.png\n",
      "ROIs para CEA TORRES BASTIAN: {'left': {'xmin': 949, 'ymin': 336, 'xmax': 1075, 'ymax': 617}, 'right': {'xmin': 1257, 'ymin': 307, 'xmax': 1386, 'ymax': 564}}\n",
      "Guardado left: CEA TORRES BASTIAN_izq.jpg, CEA TORRES BASTIAN_izq.png\n",
      "Guardado right: CEA TORRES BASTIAN_der.jpg, CEA TORRES BASTIAN_der.png\n",
      "ROIs para CELIS LOPEZ INIAKI 06-08-2009: {'left': {'xmin': 914, 'ymin': 333, 'xmax': 1083, 'ymax': 583}, 'right': {'xmin': 1342, 'ymin': 358, 'xmax': 1503, 'ymax': 611}}\n",
      "Guardado left: CELIS LOPEZ INIAKI 06-08-2009_izq.jpg, CELIS LOPEZ INIAKI 06-08-2009_izq.png\n",
      "Guardado right: CELIS LOPEZ INIAKI 06-08-2009_der.jpg, CELIS LOPEZ INIAKI 06-08-2009_der.png\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import os\n",
    "from PIL import Image\n",
    "import glob\n",
    "\n",
    "# Configuración del modelo\n",
    "CONF_THRESHOLD = 0.85\n",
    "model_path = '../../yolov5/runs/train/rx_canines_exp21/weights/best.pt'\n",
    "\n",
    "# Cargar modelo YOLOv5\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = torch.hub.load('ultralytics/yolov5', 'custom', path=model_path).to(device)\n",
    "model.conf = CONF_THRESHOLD\n",
    "\n",
    "def get_canine_rois(img_path):\n",
    "    # Cargar imagen\n",
    "    img = cv2.imread(img_path)\n",
    "    if img is None:\n",
    "        raise FileNotFoundError(f\"No se pudo leer la imagen en {img_path}\")\n",
    "    \n",
    "    # Detección\n",
    "    results = model(img)\n",
    "    df = results.pandas().xyxy[0]\n",
    "    \n",
    "    # Filtrar caninos y determinar línea media\n",
    "    canines = df[df['name'] == 'canine']\n",
    "    incisors = df[df['name'] == 'inc']\n",
    "    \n",
    "    # Calcular línea media\n",
    "    midline_x = img.shape[1] // 2  # Fallback: centro de la imagen\n",
    "    if not incisors.empty:\n",
    "        best_inc = incisors.iloc[incisors['confidence'].argmax()]\n",
    "        midline_x = (best_inc['xmin'] + best_inc['xmax']) // 2\n",
    "    \n",
    "    # Clasificar caninos\n",
    "    left_canine = None\n",
    "    right_canine = None\n",
    "    \n",
    "    for _, det in canines.iterrows():\n",
    "        cx = (det['xmin'] + det['xmax']) // 2\n",
    "        if cx < midline_x:\n",
    "            if left_canine is None or det['confidence'] > left_canine['confidence']:\n",
    "                left_canine = det\n",
    "        else:\n",
    "            if right_canine is None or det['confidence'] > right_canine['confidence']:\n",
    "                right_canine = det\n",
    "    \n",
    "    # Extraer ROIs\n",
    "    rois = {}\n",
    "    if left_canine is not None:\n",
    "        rois['left'] = {\n",
    "            'xmin': int(left_canine['xmin']),\n",
    "            'ymin': int(left_canine['ymin']),\n",
    "            'xmax': int(left_canine['xmax']),\n",
    "            'ymax': int(left_canine['ymax'])\n",
    "        }\n",
    "    \n",
    "    if right_canine is not None:\n",
    "        rois['right'] = {\n",
    "            'xmin': int(right_canine['xmin']),\n",
    "            'ymin': int(right_canine['ymin']),\n",
    "            'xmax': int(right_canine['xmax']),\n",
    "            'ymax': int(right_canine['ymax'])\n",
    "        }\n",
    "    \n",
    "    return rois\n",
    "\n",
    "# Rutas de entrada y salida\n",
    "dir_images       = '../data/asm-train'\n",
    "dir_masks        = '../data/asm-train-masks'\n",
    "dir_img_out      = '../data/asm-train-cropped/imgs'\n",
    "dir_mask_out     = '../data/asm-train-cropped/masks'\n",
    "\n",
    "# Crear carpetas de salida si no existen\n",
    "os.makedirs(dir_img_out,  exist_ok=True)\n",
    "os.makedirs(dir_mask_out, exist_ok=True)\n",
    "\n",
    "# Iterar sobre todas las imágenes JPG en el directorio\n",
    "for img_path in glob.glob(os.path.join(dir_images, '*.jpg')):\n",
    "    base = os.path.splitext(os.path.basename(img_path))[0]\n",
    "    try:\n",
    "        rois = get_canine_rois(img_path)\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR en detección para {base}: {e}\")\n",
    "        continue\n",
    "    print(f\"ROIs para {base}: {rois}\")\n",
    "\n",
    "    # Procesar cada ROI detectado\n",
    "    for side, bbox in rois.items():\n",
    "        # Definir sufijo y nombres de archivo de salida\n",
    "        suffix = 'izq' if side == 'left' else 'der'\n",
    "        img_out_name  = f\"{base}_{suffix}.jpg\"\n",
    "        mask_out_name = f\"{base}_{suffix}.png\"\n",
    "\n",
    "        # Recortar imagen original\n",
    "        img = cv2.imread(img_path)\n",
    "        x1, y1, x2, y2 = bbox['xmin'], bbox['ymin'], bbox['xmax'], bbox['ymax']\n",
    "        # Asegurarse de que las coordenadas sean enteros\n",
    "        x1, y1, x2, y2 = map(int, (x1, y1, x2, y2))\n",
    "        roi_img = img[y1:y2, x1:x2]\n",
    "        cv2.imwrite(os.path.join(dir_img_out, img_out_name), roi_img)\n",
    "\n",
    "        # Recortar máscara correspondiente\n",
    "        mask_path = os.path.join(dir_masks, base + '.png')\n",
    "        if not os.path.exists(mask_path):\n",
    "            print(f\"WARNING: Máscara faltante {mask_path}\")\n",
    "            continue\n",
    "        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "        roi_mask = mask[y1:y2, x1:x2]\n",
    "        cv2.imwrite(os.path.join(dir_mask_out, mask_out_name), roi_mask)\n",
    "\n",
    "        print(f\"Guardado {side}: {img_out_name}, {mask_out_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf407cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d19fbc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 - Loss: 1.1429 - Val IoU: 0.0631\n",
      "Epoch 2/50 - Loss: 1.1288 - Val IoU: 0.0631\n",
      "Epoch 3/50 - Loss: 1.0995 - Val IoU: 0.0001\n",
      "Epoch 4/50 - Loss: 1.0658 - Val IoU: 0.0000\n",
      "Epoch 5/50 - Loss: 1.0530 - Val IoU: 0.0000\n",
      "Epoch 6/50 - Loss: 1.0413 - Val IoU: 0.0000\n",
      "Epoch 7/50 - Loss: 1.0292 - Val IoU: 0.0000\n",
      "Epoch 8/50 - Loss: 1.1297 - Val IoU: 0.0000\n",
      "Epoch 9/50 - Loss: 1.0465 - Val IoU: 0.0000\n",
      "Epoch 10/50 - Loss: 1.0520 - Val IoU: 0.0000\n",
      "Epoch 11/50 - Loss: 1.0349 - Val IoU: 0.0000\n",
      "Epoch 12/50 - Loss: 0.9873 - Val IoU: 0.0000\n",
      "Epoch 13/50 - Loss: 0.9079 - Val IoU: 0.0000\n",
      "Epoch 14/50 - Loss: 0.8565 - Val IoU: 0.0000\n",
      "Epoch 15/50 - Loss: 0.8295 - Val IoU: 0.0837\n",
      "Epoch 16/50 - Loss: 0.8438 - Val IoU: 0.1065\n",
      "Epoch 17/50 - Loss: 0.8036 - Val IoU: 0.0995\n",
      "Epoch 18/50 - Loss: 0.7957 - Val IoU: 0.1635\n",
      "Epoch 19/50 - Loss: 0.7938 - Val IoU: 0.0934\n",
      "Epoch 20/50 - Loss: 0.7765 - Val IoU: 0.0941\n",
      "Epoch 21/50 - Loss: 0.7699 - Val IoU: 0.0943\n",
      "Epoch 22/50 - Loss: 0.7642 - Val IoU: 0.0943\n",
      "Epoch 23/50 - Loss: 0.7572 - Val IoU: 0.0947\n",
      "Epoch 24/50 - Loss: 0.7498 - Val IoU: 0.0949\n",
      "Epoch 25/50 - Loss: 0.7405 - Val IoU: 0.0955\n",
      "Epoch 26/50 - Loss: 0.7502 - Val IoU: 0.0970\n",
      "Epoch 27/50 - Loss: 0.7304 - Val IoU: 0.0966\n",
      "Epoch 28/50 - Loss: 0.7213 - Val IoU: 0.0980\n",
      "Epoch 29/50 - Loss: 0.7107 - Val IoU: 0.0987\n",
      "Epoch 30/50 - Loss: 0.7011 - Val IoU: 0.0987\n",
      "Epoch 31/50 - Loss: 0.7061 - Val IoU: 0.1043\n",
      "Epoch 32/50 - Loss: 0.6951 - Val IoU: 0.1078\n",
      "Epoch 33/50 - Loss: 0.6951 - Val IoU: 0.1171\n",
      "Epoch 34/50 - Loss: 0.6862 - Val IoU: 0.1279\n",
      "Epoch 35/50 - Loss: 0.6895 - Val IoU: 0.1174\n",
      "Epoch 36/50 - Loss: 0.6775 - Val IoU: 0.1152\n",
      "Epoch 37/50 - Loss: 0.6855 - Val IoU: 0.1164\n",
      "Epoch 38/50 - Loss: 0.6860 - Val IoU: 0.1204\n",
      "Epoch 39/50 - Loss: 0.6870 - Val IoU: 0.1464\n",
      "Epoch 40/50 - Loss: 0.6742 - Val IoU: 0.1178\n",
      "Epoch 41/50 - Loss: 0.6685 - Val IoU: 0.1224\n",
      "Epoch 42/50 - Loss: 0.6771 - Val IoU: 0.1543\n",
      "Epoch 43/50 - Loss: 0.6705 - Val IoU: 0.1466\n",
      "Epoch 44/50 - Loss: 0.6645 - Val IoU: 0.1309\n",
      "Epoch 45/50 - Loss: 0.6642 - Val IoU: 0.1282\n",
      "Epoch 46/50 - Loss: 0.6566 - Val IoU: 0.1197\n",
      "Epoch 47/50 - Loss: 0.6509 - Val IoU: 0.1214\n",
      "Epoch 48/50 - Loss: 0.6508 - Val IoU: 0.1311\n",
      "Epoch 49/50 - Loss: 0.6532 - Val IoU: 0.1414\n",
      "Epoch 50/50 - Loss: 0.6525 - Val IoU: 0.1357\n"
     ]
    }
   ],
   "source": [
    "# Entrenamiento de U-Net para segmentación de caninos (obtención de máscaras para determinar la forma)\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# ----------------------\n",
    "# Configuración general\n",
    "# ----------------------\n",
    "IMG_HEIGHT = 256\n",
    "IMG_WIDTH = 256\n",
    "BATCH_SIZE = 8\n",
    "EPOCHS = 50\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "NUM_CLASSES = 3  # fondo, canino izquierdo, canino derecho\n",
    "\n",
    "# Directorios de datos (máscaras e imágenes por separado)\n",
    "IMAGE_DIR = \"../data/asm-train-cropped/imgs\"\n",
    "MASK_DIR = \"../data/asm-train-cropped/masks\"\n",
    "\n",
    "# ----------------------\n",
    "# Dataset personalizado con etiqueta de lado\n",
    "# ----------------------\n",
    "class CanineDataset(Dataset):\n",
    "    def __init__(self, image_dir, mask_dir, transform=None):\n",
    "        self.image_paths = sorted(glob.glob(os.path.join(image_dir, \"*.jpg\")))\n",
    "        self.mask_paths = sorted(glob.glob(os.path.join(mask_dir, \"*.png\")))\n",
    "        if len(self.image_paths) != len(self.mask_paths):\n",
    "            raise RuntimeError(\"Número de imágenes y máscaras no coincide.\")\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        mask_path = self.mask_paths[idx]\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        mask = Image.open(mask_path).convert(\"L\")\n",
    "\n",
    "        # Determinar clase según nombre de archivo\n",
    "        # Asumimos sufijos '_izq' o '_der' en el nombre\n",
    "        base = os.path.basename(img_path).lower()\n",
    "        if 'izq' in base:\n",
    "            class_id = 1\n",
    "        elif 'der' in base:\n",
    "            class_id = 2\n",
    "        else:\n",
    "            class_id = 0  # fallback: fondo\n",
    "\n",
    "        # Aplicar transforms\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "            mask = self.transform(mask)\n",
    "\n",
    "        # Binarizar y convertir a etiquetas de clase\n",
    "        mask_bin = (mask > 0).long().squeeze(0)  # HxW tensor 0/1\n",
    "        mask_cls = mask_bin * class_id           # 0=fondo,1=izq,2=der\n",
    "        return img, mask_cls\n",
    "\n",
    "# ----------------------\n",
    "# Transforms\n",
    "# ----------------------\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((IMG_HEIGHT, IMG_WIDTH)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# ----------------------\n",
    "# U-Net multiclase en PyTorch\n",
    "# ----------------------\n",
    "class DoubleConv(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super().__init__()\n",
    "        self.double_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_ch, out_ch, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_ch, out_ch, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "    def forward(self, x): return self.double_conv(x)\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        # Encoder\n",
    "        self.enc1 = DoubleConv(3, 64); self.pool1 = nn.MaxPool2d(2)\n",
    "        self.enc2 = DoubleConv(64,128); self.pool2 = nn.MaxPool2d(2)\n",
    "        self.enc3 = DoubleConv(128,256); self.pool3 = nn.MaxPool2d(2)\n",
    "        self.enc4 = DoubleConv(256,512); self.pool4 = nn.MaxPool2d(2)\n",
    "        # Bottleneck\n",
    "        self.bottleneck = DoubleConv(512,1024)\n",
    "        # Decoder\n",
    "        self.up4 = nn.ConvTranspose2d(1024,512,2,2); self.dec4 = DoubleConv(1024,512)\n",
    "        self.up3 = nn.ConvTranspose2d(512,256,2,2);  self.dec3 = DoubleConv(512,256)\n",
    "        self.up2 = nn.ConvTranspose2d(256,128,2,2);  self.dec2 = DoubleConv(256,128)\n",
    "        self.up1 = nn.ConvTranspose2d(128, 64,2,2);  self.dec1 = DoubleConv(128, 64)\n",
    "        # Output\n",
    "        self.final_conv = nn.Conv2d(64, num_classes, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        s1 = self.enc1(x); p1=self.pool1(s1)\n",
    "        s2 = self.enc2(p1); p2=self.pool2(s2)\n",
    "        s3 = self.enc3(p2); p3=self.pool3(s3)\n",
    "        s4 = self.enc4(p3); p4=self.pool4(s4)\n",
    "        b  = self.bottleneck(p4)\n",
    "        d4 = self.up4(b); d4=torch.cat([d4,s4],1); d4=self.dec4(d4)\n",
    "        d3 = self.up3(d4); d3=torch.cat([d3,s3],1); d3=self.dec3(d3)\n",
    "        d2 = self.up2(d3); d2=torch.cat([d2,s2],1); d2=self.dec2(d2)\n",
    "        d1 = self.up1(d2); d1=torch.cat([d1,s1],1); d1=self.dec1(d1)\n",
    "        return self.final_conv(d1)\n",
    "\n",
    "# ----------------------\n",
    "# Métrica y pérdida\n",
    "# ----------------------\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "def iou_multiclass(pred, target, num_classes, smooth=1e-6):\n",
    "    # pred: BxHxW, target: BxHxW\n",
    "    ious = []\n",
    "    for cls in range(1, num_classes):  # ignorar fondo\n",
    "        pred_inds = (pred==cls)\n",
    "        target_inds = (target==cls)\n",
    "        intersection = (pred_inds & target_inds).sum().float()\n",
    "        union = pred_inds.sum() + target_inds.sum() - intersection\n",
    "        if union>0:\n",
    "            ious.append((intersection+smooth)/(union+smooth))\n",
    "    return torch.mean(torch.stack(ious)) if ious else torch.tensor(0.)\n",
    "\n",
    "# ----------------------\n",
    "# Preparar dataloaders\n",
    "# ----------------------\n",
    "all_dataset = CanineDataset(IMAGE_DIR, MASK_DIR, transform=transform)\n",
    "train_size = int(0.8*len(all_dataset)); val_size = len(all_dataset)-train_size\n",
    "train_ds, val_ds = random_split(all_dataset, [train_size, val_size])\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader   = DataLoader(val_ds, batch_size=BATCH_SIZE)\n",
    "\n",
    "# ----------------------\n",
    "# Entrenamiento\n",
    "# ----------------------\n",
    "model = UNet(NUM_CLASSES).to(DEVICE)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "best_iou=0.\n",
    "for epoch in range(1, EPOCHS+1):\n",
    "    model.train(); train_loss=0\n",
    "    for imgs, masks in train_loader:\n",
    "        imgs, masks = imgs.to(DEVICE), masks.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(imgs)\n",
    "        loss = criterion(logits, masks)\n",
    "        loss.backward(); optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "    train_loss /= len(train_loader)\n",
    "    # Validación\n",
    "    model.eval(); val_iou=0\n",
    "    with torch.no_grad():\n",
    "        for imgs, masks in val_loader:\n",
    "            imgs, masks = imgs.to(DEVICE), masks.to(DEVICE)\n",
    "            logits = model(imgs)\n",
    "            preds = torch.argmax(logits, dim=1)\n",
    "            val_iou += iou_multiclass(preds, masks, NUM_CLASSES)\n",
    "    val_iou /= len(val_loader)\n",
    "    print(f\"Epoch {epoch}/{EPOCHS} - Loss: {train_loss:.4f} - Val IoU: {val_iou:.4f}\")\n",
    "    if val_iou>best_iou:\n",
    "        best_iou=val_iou\n",
    "        torch.save(model.state_dict(), \"unet_best.pth\")\n",
    "# Guardar final\n",
    "torch.save(model.state_dict(), \"../models/unet_final.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1e5237",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Renombrado completo.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "carpeta = 'img_test'\n",
    "\n",
    "extensiones_validas = ['.jpg', '.jpeg', '.png', '.bmp', '.tiff']\n",
    "imagenes = [f for f in os.listdir(carpeta) if os.path.splitext(f)[1].lower() in extensiones_validas]\n",
    "\n",
    "imagenes.sort()\n",
    "\n",
    "# Renombrar\n",
    "for i, nombre in enumerate(imagenes, start=1):\n",
    "    _, extension = os.path.splitext(nombre)\n",
    "    nuevo_nombre = f'foto_{i}{extension.lower()}'\n",
    "    ruta_original = os.path.join(carpeta, nombre)\n",
    "    ruta_nueva = os.path.join(carpeta, nuevo_nombre)\n",
    "    os.rename(ruta_original, ruta_nueva)\n",
    "\n",
    "print(\"Renombrado completo.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b22717",
   "metadata": {},
   "outputs": [],
   "source": [
    "#img_path = 'img_test/foto2.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea739109",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/ultralytics/yolov5/zipball/master\" to C:\\Users\\josem/.cache\\torch\\hub\\master.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5  2025-6-20 Python-3.12.3 torch-2.7.1+cpu CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 157 layers, 7015519 parameters, 0 gradients, 15.8 GFLOPs\n",
      "Adding AutoShape... \n",
      "C:\\Users\\josem/.cache\\torch\\hub\\ultralytics_yolov5_master\\models\\common.py:906: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Umbral de confianza ajustado a: 0.85\n",
      "\n",
      "Procesando: foto1.jpg\n",
      "\n",
      "=== RESULTADOS DE DETECCIÓN ===\n",
      "          xmin        ymin         xmax        ymax  confidence  class    name\n",
      "0  1137.677368  463.714294  1307.943481  780.272339    0.937926      1     inc\n",
      "1   994.286987  339.954651  1124.865356  613.205200    0.917207      0  canine\n",
      "2  1336.144165  352.465576  1449.814331  663.742249    0.908585      0  canine\n",
      "Línea media trazada en x=1222\n",
      "Guardado en: Output/prueba_original\\foto1_analizada.jpg\n",
      "\n",
      "Procesando: foto10.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\josem/.cache\\torch\\hub\\ultralytics_yolov5_master\\models\\common.py:906: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== RESULTADOS DE DETECCIÓN ===\n",
      "          xmin        ymin         xmax        ymax  confidence  class    name\n",
      "0  1246.987183  418.803253  1460.562622  798.740723    0.942660      1     inc\n",
      "1  1489.395142  339.977325  1613.982544  644.122498    0.900618      0  canine\n",
      "2  1092.369263  380.337952  1222.099854  653.845825    0.899928      0  canine\n",
      "Línea media trazada en x=1353\n",
      "Guardado en: Output/prueba_original\\foto10_analizada.jpg\n",
      "\n",
      "Procesando: foto11.jpg\n",
      "\n",
      "=== RESULTADOS DE DETECCIÓN ===\n",
      "          xmin        ymin         xmax        ymax  confidence  class    name\n",
      "0  1349.335693  350.710327  1485.983765  579.064453    0.943251      0  canine\n",
      "1  1141.372681  461.526428  1339.669678  788.097168    0.935345      1     inc\n",
      "2   987.672791  347.348694  1132.145996  560.624512    0.905195      0  canine\n",
      "Línea media trazada en x=1240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\josem/.cache\\torch\\hub\\ultralytics_yolov5_master\\models\\common.py:906: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guardado en: Output/prueba_original\\foto11_analizada.jpg\n",
      "\n",
      "Procesando: foto12.jpg\n",
      "\n",
      "=== RESULTADOS DE DETECCIÓN ===\n",
      "          xmin        ymin         xmax        ymax  confidence  class name\n",
      "0  1242.397949  432.810486  1453.666504  789.500183    0.939164      1  inc\n",
      "Línea media trazada en x=1347\n",
      "Guardado en: Output/prueba_original\\foto12_analizada.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\josem/.cache\\torch\\hub\\ultralytics_yolov5_master\\models\\common.py:906: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Procesando: foto13.jpg\n",
      "\n",
      "=== RESULTADOS DE DETECCIÓN ===\n",
      "          xmin        ymin         xmax        ymax  confidence  class    name\n",
      "0  1274.258179  374.519135  1368.260864  547.362488    0.904615      0  canine\n",
      "1   978.473328  391.249451  1078.918945  536.221130    0.886914      0  canine\n",
      "No se detectaron incisivos; no se puede trazar la línea media.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\josem/.cache\\torch\\hub\\ultralytics_yolov5_master\\models\\common.py:906: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Procesando: foto14.jpg\n",
      "\n",
      "=== RESULTADOS DE DETECCIÓN ===\n",
      "          xmin        ymin         xmax        ymax  confidence  class    name\n",
      "0  1026.081543  361.115204  1144.400391  609.286621    0.912738      0  canine\n",
      "1  1352.676758  366.415710  1453.461182  641.877075    0.880602      0  canine\n",
      "2  1161.709717  473.198425  1331.247314  773.760315    0.878758      1     inc\n",
      "Línea media trazada en x=1246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\josem/.cache\\torch\\hub\\ultralytics_yolov5_master\\models\\common.py:906: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guardado en: Output/prueba_original\\foto14_analizada.jpg\n",
      "\n",
      "Procesando: foto15.jpg\n",
      "\n",
      "=== RESULTADOS DE DETECCIÓN ===\n",
      "          xmin        ymin         xmax        ymax  confidence  class    name\n",
      "0  1179.479492  462.349243  1354.561768  787.266663    0.957070      1     inc\n",
      "1  1043.341797  387.434570  1166.548218  619.814880    0.925374      0  canine\n",
      "2  1369.964111  378.957733  1480.934570  636.849854    0.889730      0  canine\n",
      "Línea media trazada en x=1266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\josem/.cache\\torch\\hub\\ultralytics_yolov5_master\\models\\common.py:906: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guardado en: Output/prueba_original\\foto15_analizada.jpg\n",
      "\n",
      "Procesando: foto16.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\josem/.cache\\torch\\hub\\ultralytics_yolov5_master\\models\\common.py:906: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== RESULTADOS DE DETECCIÓN ===\n",
      "Empty DataFrame\n",
      "Columns: [xmin, ymin, xmax, ymax, confidence, class, name]\n",
      "Index: []\n",
      "No se detectaron incisivos; no se puede trazar la línea media.\n",
      "\n",
      "Procesando: foto17.jpg\n",
      "\n",
      "=== RESULTADOS DE DETECCIÓN ===\n",
      "          xmin        ymin         xmax        ymax  confidence  class    name\n",
      "0   997.016296  297.236633  1153.750488  614.318481    0.920587      0  canine\n",
      "1  1149.034790  468.941772  1333.407959  778.290405    0.898848      1     inc\n",
      "2  1337.463257  322.572723  1464.901245  623.660400    0.884615      0  canine\n",
      "Línea media trazada en x=1241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\josem/.cache\\torch\\hub\\ultralytics_yolov5_master\\models\\common.py:906: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guardado en: Output/prueba_original\\foto17_analizada.jpg\n",
      "\n",
      "Procesando: foto18.jpg\n",
      "\n",
      "=== RESULTADOS DE DETECCIÓN ===\n",
      "          xmin        ymin         xmax        ymax  confidence  class    name\n",
      "0  1036.296509  362.297638  1138.063599  628.227234    0.926872      0  canine\n",
      "1  1148.819458  476.611145  1305.037964  785.926514    0.910295      1     inc\n",
      "2  1320.228760  342.293945  1426.796265  609.092957    0.907599      0  canine\n",
      "Línea media trazada en x=1226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\josem/.cache\\torch\\hub\\ultralytics_yolov5_master\\models\\common.py:906: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guardado en: Output/prueba_original\\foto18_analizada.jpg\n",
      "\n",
      "Procesando: foto19.jpg\n",
      "\n",
      "=== RESULTADOS DE DETECCIÓN ===\n",
      "Empty DataFrame\n",
      "Columns: [xmin, ymin, xmax, ymax, confidence, class, name]\n",
      "Index: []\n",
      "No se detectaron incisivos; no se puede trazar la línea media.\n",
      "\n",
      "Procesando: foto2.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\josem/.cache\\torch\\hub\\ultralytics_yolov5_master\\models\\common.py:906: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n",
      "C:\\Users\\josem/.cache\\torch\\hub\\ultralytics_yolov5_master\\models\\common.py:906: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== RESULTADOS DE DETECCIÓN ===\n",
      "          xmin        ymin         xmax        ymax  confidence  class    name\n",
      "0  1140.040405  453.257843  1331.111938  790.877014    0.932662      1     inc\n",
      "1  1324.422363  335.785797  1441.857788  597.410034    0.916977      0  canine\n",
      "Línea media trazada en x=1235\n",
      "Guardado en: Output/prueba_original\\foto2_analizada.jpg\n",
      "\n",
      "Procesando: foto20.jpg\n",
      "\n",
      "=== RESULTADOS DE DETECCIÓN ===\n",
      "          xmin        ymin         xmax        ymax  confidence  class    name\n",
      "0  1200.395020  457.182251  1395.696411  793.591187    0.943054      1     inc\n",
      "1  1404.829590  323.797150  1542.386841  565.351990    0.918706      0  canine\n",
      "2  1058.688232  334.178589  1183.568604  589.685974    0.915419      0  canine\n",
      "Línea media trazada en x=1297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\josem/.cache\\torch\\hub\\ultralytics_yolov5_master\\models\\common.py:906: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guardado en: Output/prueba_original\\foto20_analizada.jpg\n",
      "\n",
      "Procesando: foto21.jpg\n",
      "\n",
      "=== RESULTADOS DE DETECCIÓN ===\n",
      "          xmin        ymin         xmax        ymax  confidence  class    name\n",
      "0  1112.206421  452.039856  1304.954590  800.259399    0.934671      1     inc\n",
      "1   963.624084  377.254242  1078.725586  680.359619    0.857412      0  canine\n",
      "Línea media trazada en x=1208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\josem/.cache\\torch\\hub\\ultralytics_yolov5_master\\models\\common.py:906: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guardado en: Output/prueba_original\\foto21_analizada.jpg\n",
      "\n",
      "Procesando: foto22.jpg\n",
      "\n",
      "=== RESULTADOS DE DETECCIÓN ===\n",
      "Empty DataFrame\n",
      "Columns: [xmin, ymin, xmax, ymax, confidence, class, name]\n",
      "Index: []\n",
      "No se detectaron incisivos; no se puede trazar la línea media.\n",
      "\n",
      "Procesando: foto23.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\josem/.cache\\torch\\hub\\ultralytics_yolov5_master\\models\\common.py:906: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n",
      "C:\\Users\\josem/.cache\\torch\\hub\\ultralytics_yolov5_master\\models\\common.py:906: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== RESULTADOS DE DETECCIÓN ===\n",
      "          xmin        ymin         xmax        ymax  confidence  class    name\n",
      "0  1145.182251  475.498932  1316.268311  785.562683    0.940118      1     inc\n",
      "1  1322.367065  357.519836  1458.661499  607.796692    0.918486      0  canine\n",
      "2  1002.607056  370.294159  1137.910767  603.191040    0.910153      0  canine\n",
      "Línea media trazada en x=1230\n",
      "Guardado en: Output/prueba_original\\foto23_analizada.jpg\n",
      "\n",
      "Procesando: foto24.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\josem/.cache\\torch\\hub\\ultralytics_yolov5_master\\models\\common.py:906: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== RESULTADOS DE DETECCIÓN ===\n",
      "          xmin        ymin         xmax        ymax  confidence  class    name\n",
      "0  1033.228516  359.302856  1129.893555  561.542908    0.909571      0  canine\n",
      "1  1131.591675  485.932495  1283.670654  785.416382    0.897949      1     inc\n",
      "2  1300.725342  393.049164  1383.781860  580.536682    0.879223      0  canine\n",
      "Línea media trazada en x=1207\n",
      "Guardado en: Output/prueba_original\\foto24_analizada.jpg\n",
      "\n",
      "Procesando: foto25.jpg\n",
      "\n",
      "=== RESULTADOS DE DETECCIÓN ===\n",
      "          xmin        ymin         xmax        ymax  confidence  class    name\n",
      "0  1301.740845  395.283569  1413.645874  621.343018    0.905122      0  canine\n",
      "1  1137.399780  533.077393  1287.277344  779.344788    0.904445      1     inc\n",
      "2  1030.190063  402.642273  1131.679565  642.438660    0.893085      0  canine\n",
      "Línea media trazada en x=1212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\josem/.cache\\torch\\hub\\ultralytics_yolov5_master\\models\\common.py:906: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guardado en: Output/prueba_original\\foto25_analizada.jpg\n",
      "\n",
      "Procesando: foto26.jpg\n",
      "\n",
      "=== RESULTADOS DE DETECCIÓN ===\n",
      "          xmin        ymin         xmax        ymax  confidence  class    name\n",
      "0  1171.465210  492.584961  1342.126343  774.430725    0.910214      1     inc\n",
      "1  1359.771729  365.420685  1460.013184  655.923096    0.897690      0  canine\n",
      "Línea media trazada en x=1256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\josem/.cache\\torch\\hub\\ultralytics_yolov5_master\\models\\common.py:906: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guardado en: Output/prueba_original\\foto26_analizada.jpg\n",
      "\n",
      "Procesando: foto27.jpg\n",
      "\n",
      "=== RESULTADOS DE DETECCIÓN ===\n",
      "          xmin        ymin         xmax        ymax  confidence  class    name\n",
      "0  1230.637451  404.440460  1426.686401  774.218933    0.936572      1     inc\n",
      "1  1452.493530  350.555664  1575.639526  622.245972    0.909898      0  canine\n",
      "2  1088.313354  362.276947  1209.281006  641.075134    0.892518      0  canine\n",
      "Línea media trazada en x=1328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\josem/.cache\\torch\\hub\\ultralytics_yolov5_master\\models\\common.py:906: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guardado en: Output/prueba_original\\foto27_analizada.jpg\n",
      "\n",
      "Procesando: foto28.jpg\n",
      "\n",
      "=== RESULTADOS DE DETECCIÓN ===\n",
      "          xmin        ymin         xmax        ymax  confidence  class    name\n",
      "0  1121.699097  481.384399  1313.048706  781.467651    0.924658      1     inc\n",
      "1  1342.147705  387.811737  1470.959229  557.930603    0.884583      0  canine\n",
      "2   988.884460  365.688019  1107.958130  528.191589    0.879466      0  canine\n",
      "Línea media trazada en x=1217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\josem/.cache\\torch\\hub\\ultralytics_yolov5_master\\models\\common.py:906: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guardado en: Output/prueba_original\\foto28_analizada.jpg\n",
      "\n",
      "Procesando: foto29.jpg\n",
      "\n",
      "=== RESULTADOS DE DETECCIÓN ===\n",
      "          xmin        ymin         xmax        ymax  confidence  class    name\n",
      "0  1296.446411  342.566528  1446.878540  614.774109    0.909454      0  canine\n",
      "1   997.741699  358.394806  1123.552124  629.900452    0.904252      0  canine\n",
      "2  1133.324707  488.733765  1306.038574  792.920410    0.894344      1     inc\n",
      "Línea media trazada en x=1219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\josem/.cache\\torch\\hub\\ultralytics_yolov5_master\\models\\common.py:906: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guardado en: Output/prueba_original\\foto29_analizada.jpg\n",
      "\n",
      "Procesando: foto3.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\josem/.cache\\torch\\hub\\ultralytics_yolov5_master\\models\\common.py:906: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== RESULTADOS DE DETECCIÓN ===\n",
      "          xmin        ymin         xmax        ymax  confidence  class    name\n",
      "0  1121.355713  481.247345  1316.243896  761.721375    0.910407      1     inc\n",
      "1  1334.326050  391.198853  1451.810425  583.955444    0.883845      0  canine\n",
      "2   977.313599  399.362244  1089.722778  577.399536    0.879918      0  canine\n",
      "Línea media trazada en x=1218\n",
      "Guardado en: Output/prueba_original\\foto3_analizada.jpg\n",
      "\n",
      "Procesando: foto30.jpg\n",
      "\n",
      "=== RESULTADOS DE DETECCIÓN ===\n",
      "          xmin        ymin         xmax        ymax  confidence  class    name\n",
      "0  1252.155640  383.832886  1381.892944  648.699829    0.904537      0  canine\n",
      "1   999.098816  406.932343  1103.992554  669.723633    0.891562      0  canine\n",
      "2  1111.626099  481.621277  1252.057739  799.325500    0.858458      1     inc\n",
      "Línea media trazada en x=1181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\josem/.cache\\torch\\hub\\ultralytics_yolov5_master\\models\\common.py:906: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guardado en: Output/prueba_original\\foto30_analizada.jpg\n",
      "\n",
      "Procesando: foto31.jpg\n",
      "\n",
      "=== RESULTADOS DE DETECCIÓN ===\n",
      "          xmin        ymin         xmax        ymax  confidence  class name\n",
      "0  1122.756958  412.718658  1326.358765  780.362915     0.90024      1  inc\n",
      "Línea media trazada en x=1224\n",
      "Guardado en: Output/prueba_original\\foto31_analizada.jpg\n",
      "\n",
      "Procesando: foto32.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\josem/.cache\\torch\\hub\\ultralytics_yolov5_master\\models\\common.py:906: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n",
      "C:\\Users\\josem/.cache\\torch\\hub\\ultralytics_yolov5_master\\models\\common.py:906: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== RESULTADOS DE DETECCIÓN ===\n",
      "          xmin        ymin         xmax        ymax  confidence  class    name\n",
      "0  1151.001953  489.665192  1324.769653  779.063477    0.909157      1     inc\n",
      "1  1356.315186  406.778748  1456.190918  582.260010    0.885419      0  canine\n",
      "2  1032.797852  392.301544  1142.034424  561.958862    0.860771      0  canine\n",
      "Línea media trazada en x=1237\n",
      "Guardado en: Output/prueba_original\\foto32_analizada.jpg\n",
      "\n",
      "Procesando: foto33.jpg\n",
      "\n",
      "=== RESULTADOS DE DETECCIÓN ===\n",
      "          xmin        ymin         xmax        ymax  confidence  class    name\n",
      "0  1106.936157  445.361298  1286.284058  785.101624    0.934923      1     inc\n",
      "1   982.964294  335.998474  1097.080078  553.448059    0.910484      0  canine\n",
      "2  1294.287598  322.919739  1418.490112  526.639343    0.902848      0  canine\n",
      "Línea media trazada en x=1196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\josem/.cache\\torch\\hub\\ultralytics_yolov5_master\\models\\common.py:906: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guardado en: Output/prueba_original\\foto33_analizada.jpg\n",
      "\n",
      "Procesando: foto34.jpg\n",
      "\n",
      "=== RESULTADOS DE DETECCIÓN ===\n",
      "          xmin        ymin         xmax        ymax  confidence  class    name\n",
      "0  1440.632080  393.572906  1557.852295  691.066101    0.908556      0  canine\n",
      "1  1228.668091  497.625824  1404.902954  780.648743    0.868762      1     inc\n",
      "2  1048.577637  354.073151  1232.644775  560.156616    0.853660      0  canine\n",
      "Línea media trazada en x=1316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\josem/.cache\\torch\\hub\\ultralytics_yolov5_master\\models\\common.py:906: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guardado en: Output/prueba_original\\foto34_analizada.jpg\n",
      "\n",
      "Procesando: foto35.jpg\n",
      "\n",
      "=== RESULTADOS DE DETECCIÓN ===\n",
      "          xmin        ymin         xmax        ymax  confidence  class name\n",
      "0  1118.254517  451.495239  1319.500122  780.865906    0.876957      1  inc\n",
      "Línea media trazada en x=1218\n",
      "Guardado en: Output/prueba_original\\foto35_analizada.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\josem/.cache\\torch\\hub\\ultralytics_yolov5_master\\models\\common.py:906: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Procesando: foto36.jpg\n",
      "\n",
      "=== RESULTADOS DE DETECCIÓN ===\n",
      "          xmin        ymin         xmax        ymax  confidence  class    name\n",
      "0  1131.482178  416.030670  1313.789917  773.982605    0.912258      1     inc\n",
      "1   990.731506  301.926270  1118.726440  563.625488    0.905112      0  canine\n",
      "2  1338.159912  301.704376  1459.860596  584.347595    0.884056      0  canine\n",
      "Línea media trazada en x=1222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\josem/.cache\\torch\\hub\\ultralytics_yolov5_master\\models\\common.py:906: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guardado en: Output/prueba_original\\foto36_analizada.jpg\n",
      "\n",
      "Procesando: foto37.jpg\n",
      "\n",
      "=== RESULTADOS DE DETECCIÓN ===\n",
      "          xmin        ymin         xmax        ymax  confidence  class    name\n",
      "0   997.713928  329.595184  1113.479492  610.134216    0.920904      0  canine\n",
      "1  1130.042847  441.548645  1312.726440  780.855347    0.920330      1     inc\n",
      "2  1337.727417  330.821838  1453.184204  628.209778    0.901132      0  canine\n",
      "Línea media trazada en x=1221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\josem/.cache\\torch\\hub\\ultralytics_yolov5_master\\models\\common.py:906: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guardado en: Output/prueba_original\\foto37_analizada.jpg\n",
      "\n",
      "Procesando: foto38.jpg\n",
      "\n",
      "=== RESULTADOS DE DETECCIÓN ===\n",
      "          xmin        ymin         xmax        ymax  confidence  class    name\n",
      "0  1089.805664  381.830109  1200.122314  674.706238    0.882407      0  canine\n",
      "1  1438.202637  331.810913  1553.060425  698.025269    0.870794      0  canine\n",
      "2  1232.000122  386.884277  1407.817139  764.632996    0.858645      1     inc\n",
      "Línea media trazada en x=1319\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\josem/.cache\\torch\\hub\\ultralytics_yolov5_master\\models\\common.py:906: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guardado en: Output/prueba_original\\foto38_analizada.jpg\n",
      "\n",
      "Procesando: foto39.jpg\n",
      "\n",
      "=== RESULTADOS DE DETECCIÓN ===\n",
      "          xmin        ymin         xmax        ymax  confidence  class    name\n",
      "0   976.333984  355.700775  1112.816040  629.792236    0.922722      0  canine\n",
      "1  1126.980835  483.035980  1319.081787  783.418152    0.917229      1     inc\n",
      "2  1324.923340  359.244141  1471.766479  622.421509    0.893431      0  canine\n",
      "Línea media trazada en x=1222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\josem/.cache\\torch\\hub\\ultralytics_yolov5_master\\models\\common.py:906: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guardado en: Output/prueba_original\\foto39_analizada.jpg\n",
      "\n",
      "Procesando: foto4.jpg\n",
      "\n",
      "=== RESULTADOS DE DETECCIÓN ===\n",
      "          xmin        ymin         xmax        ymax  confidence  class    name\n",
      "0   955.424561  373.640839  1079.411377  674.672668    0.901258      0  canine\n",
      "1  1114.043579  421.758972  1315.857300  793.897522    0.898008      1     inc\n",
      "Línea media trazada en x=1214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\josem/.cache\\torch\\hub\\ultralytics_yolov5_master\\models\\common.py:906: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guardado en: Output/prueba_original\\foto4_analizada.jpg\n",
      "\n",
      "Procesando: foto40.jpg\n",
      "\n",
      "=== RESULTADOS DE DETECCIÓN ===\n",
      "         xmin        ymin         xmax        ymax  confidence  class name\n",
      "0  1147.44873  449.869324  1301.656982  746.921692    0.920022      1  inc\n",
      "Línea media trazada en x=1224\n",
      "Guardado en: Output/prueba_original\\foto40_analizada.jpg\n",
      "\n",
      "Procesando: foto41.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\josem/.cache\\torch\\hub\\ultralytics_yolov5_master\\models\\common.py:906: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n",
      "C:\\Users\\josem/.cache\\torch\\hub\\ultralytics_yolov5_master\\models\\common.py:906: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== RESULTADOS DE DETECCIÓN ===\n",
      "          xmin        ymin         xmax        ymax  confidence  class    name\n",
      "0  1121.891602  446.330170  1320.119019  780.095337    0.933864      1     inc\n",
      "1   984.930359  301.272888  1125.026489  556.622559    0.911108      0  canine\n",
      "2  1324.571289  325.936127  1459.107178  593.615356    0.903192      0  canine\n",
      "Línea media trazada en x=1220\n",
      "Guardado en: Output/prueba_original\\foto41_analizada.jpg\n",
      "\n",
      "Procesando: foto42.jpg\n",
      "\n",
      "=== RESULTADOS DE DETECCIÓN ===\n",
      "        xmin        ymin         xmax       ymax  confidence  class    name\n",
      "0  952.97583  402.458313  1061.990845  551.22406    0.856077      0  canine\n",
      "No se detectaron incisivos; no se puede trazar la línea media.\n",
      "\n",
      "Procesando: foto43.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\josem/.cache\\torch\\hub\\ultralytics_yolov5_master\\models\\common.py:906: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n",
      "C:\\Users\\josem/.cache\\torch\\hub\\ultralytics_yolov5_master\\models\\common.py:906: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== RESULTADOS DE DETECCIÓN ===\n",
      "          xmin        ymin         xmax        ymax  confidence  class    name\n",
      "0  1134.062744  475.829773  1317.363159  774.863586    0.930130      1     inc\n",
      "1  1019.236450  353.356628  1133.008789  584.575928    0.925808      0  canine\n",
      "2  1319.722534  357.965088  1441.385132  577.528931    0.918956      0  canine\n",
      "Línea media trazada en x=1225\n",
      "Guardado en: Output/prueba_original\\foto43_analizada.jpg\n",
      "\n",
      "Procesando: foto44.jpg\n",
      "\n",
      "=== RESULTADOS DE DETECCIÓN ===\n",
      "          xmin        ymin         xmax        ymax  confidence  class    name\n",
      "0  1157.519775  439.087738  1339.638794  763.122314    0.923484      1     inc\n",
      "1  1370.720581  333.555603  1496.858765  616.574890    0.904582      0  canine\n",
      "2   998.620728  304.776001  1151.868164  592.553406    0.901422      0  canine\n",
      "Línea media trazada en x=1248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\josem/.cache\\torch\\hub\\ultralytics_yolov5_master\\models\\common.py:906: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guardado en: Output/prueba_original\\foto44_analizada.jpg\n",
      "\n",
      "Procesando: foto45.jpg\n",
      "\n",
      "=== RESULTADOS DE DETECCIÓN ===\n",
      "          xmin        ymin         xmax        ymax  confidence  class    name\n",
      "0  1132.999878  505.890198  1312.942871  788.808594    0.907454      1     inc\n",
      "1  1326.262451  384.778656  1468.484253  605.522827    0.894752      0  canine\n",
      "2   983.718140  412.645325  1117.430908  634.204407    0.890886      0  canine\n",
      "Línea media trazada en x=1222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\josem/.cache\\torch\\hub\\ultralytics_yolov5_master\\models\\common.py:906: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guardado en: Output/prueba_original\\foto45_analizada.jpg\n",
      "\n",
      "Procesando: foto46.jpg\n",
      "\n",
      "=== RESULTADOS DE DETECCIÓN ===\n",
      "          xmin        ymin         xmax        ymax  confidence  class    name\n",
      "0  1154.096802  425.138336  1366.264160  790.587891    0.954683      1     inc\n",
      "1   995.153198  347.465973  1146.062256  585.252319    0.902312      0  canine\n",
      "2  1388.315430  384.598572  1522.994629  632.266846    0.900441      0  canine\n",
      "Línea media trazada en x=1260\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\josem/.cache\\torch\\hub\\ultralytics_yolov5_master\\models\\common.py:906: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guardado en: Output/prueba_original\\foto46_analizada.jpg\n",
      "\n",
      "Procesando: foto47.jpg\n",
      "\n",
      "=== RESULTADOS DE DETECCIÓN ===\n",
      "          xmin        ymin         xmax        ymax  confidence  class    name\n",
      "0  1135.627808  434.937653  1337.305420  789.313660    0.950086      1     inc\n",
      "1   991.718811  351.877563  1116.114258  568.053467    0.917431      0  canine\n",
      "2  1376.519775  387.651825  1503.298462  593.840088    0.914247      0  canine\n",
      "Línea media trazada en x=1236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\josem/.cache\\torch\\hub\\ultralytics_yolov5_master\\models\\common.py:906: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guardado en: Output/prueba_original\\foto47_analizada.jpg\n",
      "\n",
      "Procesando: foto48.jpg\n",
      "\n",
      "=== RESULTADOS DE DETECCIÓN ===\n",
      "          xmin        ymin         xmax        ymax  confidence  class    name\n",
      "0  1053.065552  448.488770  1224.739502  790.218384    0.929446      1     inc\n",
      "1  1230.764038  380.677429  1357.530884  649.253052    0.858220      0  canine\n",
      "Línea media trazada en x=1138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\josem/.cache\\torch\\hub\\ultralytics_yolov5_master\\models\\common.py:906: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guardado en: Output/prueba_original\\foto48_analizada.jpg\n",
      "\n",
      "Procesando: foto49.jpg\n",
      "\n",
      "=== RESULTADOS DE DETECCIÓN ===\n",
      "          xmin        ymin         xmax        ymax  confidence  class    name\n",
      "0  1152.619751  471.081299  1308.620728  790.505005    0.941492      1     inc\n",
      "1  1000.986450  341.888245  1143.731567  580.927368    0.913897      0  canine\n",
      "2  1323.449951  360.133301  1438.000000  630.552917    0.904726      0  canine\n",
      "Línea media trazada en x=1230\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\josem/.cache\\torch\\hub\\ultralytics_yolov5_master\\models\\common.py:906: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guardado en: Output/prueba_original\\foto49_analizada.jpg\n",
      "\n",
      "Procesando: foto5.jpg\n",
      "\n",
      "=== RESULTADOS DE DETECCIÓN ===\n",
      "Empty DataFrame\n",
      "Columns: [xmin, ymin, xmax, ymax, confidence, class, name]\n",
      "Index: []\n",
      "No se detectaron incisivos; no se puede trazar la línea media.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\josem/.cache\\torch\\hub\\ultralytics_yolov5_master\\models\\common.py:906: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n",
      "C:\\Users\\josem/.cache\\torch\\hub\\ultralytics_yolov5_master\\models\\common.py:906: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Procesando: foto50.jpg\n",
      "\n",
      "=== RESULTADOS DE DETECCIÓN ===\n",
      "          xmin        ymin         xmax        ymax  confidence  class    name\n",
      "0  1346.198975  390.407379  1491.329468  679.730896    0.927370      0  canine\n",
      "1  1151.017578  453.581207  1320.290283  769.502869    0.927197      1     inc\n",
      "2   989.936584  396.642548  1123.653564  687.357422    0.904026      0  canine\n",
      "Línea media trazada en x=1235\n",
      "Guardado en: Output/prueba_original\\foto50_analizada.jpg\n",
      "\n",
      "Procesando: foto51.jpg\n",
      "\n",
      "=== RESULTADOS DE DETECCIÓN ===\n",
      "          xmin        ymin         xmax        ymax  confidence  class    name\n",
      "0   992.895325  319.201935  1117.770264  619.357300    0.922442      0  canine\n",
      "1  1123.849121  427.840057  1319.619507  798.614441    0.918261      1     inc\n",
      "2  1338.328247  351.183472  1455.415039  651.675354    0.892262      0  canine\n",
      "Línea media trazada en x=1221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\josem/.cache\\torch\\hub\\ultralytics_yolov5_master\\models\\common.py:906: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guardado en: Output/prueba_original\\foto51_analizada.jpg\n",
      "\n",
      "Procesando: foto52.jpg\n",
      "\n",
      "=== RESULTADOS DE DETECCIÓN ===\n",
      "          xmin        ymin         xmax        ymax  confidence  class    name\n",
      "0  1329.739624  318.538544  1450.026978  515.207336    0.918152      0  canine\n",
      "1   994.196472  303.615601  1105.021973  506.170380    0.912839      0  canine\n",
      "2  1117.776001  394.826599  1316.005981  677.952087    0.865206      1     inc\n",
      "Línea media trazada en x=1216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\josem/.cache\\torch\\hub\\ultralytics_yolov5_master\\models\\common.py:906: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guardado en: Output/prueba_original\\foto52_analizada.jpg\n",
      "\n",
      "Procesando: foto53.jpg\n",
      "\n",
      "=== RESULTADOS DE DETECCIÓN ===\n",
      "          xmin        ymin         xmax        ymax  confidence  class    name\n",
      "0  1059.300781  319.592499  1203.648071  535.160278    0.938282      0  canine\n",
      "1  1432.207642  318.123047  1568.272339  555.647034    0.926415      0  canine\n",
      "2  1223.306274  436.965302  1422.637817  780.829590    0.906035      1     inc\n",
      "Línea media trazada en x=1322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\josem/.cache\\torch\\hub\\ultralytics_yolov5_master\\models\\common.py:906: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guardado en: Output/prueba_original\\foto53_analizada.jpg\n",
      "\n",
      "Procesando: foto54.jpg\n",
      "\n",
      "=== RESULTADOS DE DETECCIÓN ===\n",
      "          xmin        ymin         xmax        ymax  confidence  class    name\n",
      "0  1131.662476  469.331879  1296.474243  779.653931    0.947001      1     inc\n",
      "1  1296.014893  359.656708  1431.188843  551.426086    0.907560      0  canine\n",
      "2  1018.227051  379.072540  1119.783447  557.293518    0.874250      0  canine\n",
      "Línea media trazada en x=1213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\josem/.cache\\torch\\hub\\ultralytics_yolov5_master\\models\\common.py:906: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guardado en: Output/prueba_original\\foto54_analizada.jpg\n",
      "\n",
      "Procesando: foto55.jpg\n",
      "\n",
      "=== RESULTADOS DE DETECCIÓN ===\n",
      "          xmin        ymin         xmax        ymax  confidence  class    name\n",
      "0  1249.629517  507.019928  1427.616333  782.872925    0.923304      1     inc\n",
      "1  1443.158447  381.843384  1541.684937  645.172180    0.893465      0  canine\n",
      "Línea media trazada en x=1338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\josem/.cache\\torch\\hub\\ultralytics_yolov5_master\\models\\common.py:906: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guardado en: Output/prueba_original\\foto55_analizada.jpg\n",
      "\n",
      "Procesando: foto56.jpg\n",
      "\n",
      "=== RESULTADOS DE DETECCIÓN ===\n",
      "          xmin        ymin         xmax        ymax  confidence  class    name\n",
      "0  1097.366943  501.208313  1266.246948  791.685486    0.916372      1     inc\n",
      "1  1269.468140  375.153687  1372.328735  564.995117    0.901842      0  canine\n",
      "2   985.751282  389.660889  1092.915283  572.048462    0.885495      0  canine\n",
      "Línea media trazada en x=1181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\josem/.cache\\torch\\hub\\ultralytics_yolov5_master\\models\\common.py:906: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guardado en: Output/prueba_original\\foto56_analizada.jpg\n",
      "\n",
      "Procesando: foto57.jpg\n",
      "\n",
      "=== RESULTADOS DE DETECCIÓN ===\n",
      "          xmin        ymin         xmax        ymax  confidence  class    name\n",
      "0  1154.734131  469.353424  1332.805420  797.602478    0.913853      1     inc\n",
      "1  1345.880493  375.977814  1456.501465  623.703674    0.909304      0  canine\n",
      "2  1033.809570  380.557526  1152.608765  599.468994    0.907972      0  canine\n",
      "Línea media trazada en x=1243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\josem/.cache\\torch\\hub\\ultralytics_yolov5_master\\models\\common.py:906: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guardado en: Output/prueba_original\\foto57_analizada.jpg\n",
      "\n",
      "Procesando: foto58.jpg\n",
      "\n",
      "=== RESULTADOS DE DETECCIÓN ===\n",
      "          xmin        ymin         xmax        ymax  confidence  class    name\n",
      "0  1022.211853  342.375397  1160.242065  608.909851    0.923203      0  canine\n",
      "1  1164.048950  458.197998  1325.623657  775.632019    0.912609      1     inc\n",
      "2  1339.944824  337.113983  1452.777222  618.205078    0.909431      0  canine\n",
      "Línea media trazada en x=1244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\josem/.cache\\torch\\hub\\ultralytics_yolov5_master\\models\\common.py:906: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guardado en: Output/prueba_original\\foto58_analizada.jpg\n",
      "\n",
      "Procesando: foto59.jpg\n",
      "\n",
      "=== RESULTADOS DE DETECCIÓN ===\n",
      "          xmin        ymin         xmax        ymax  confidence  class    name\n",
      "0  1117.953857  441.339355  1329.269409  797.034912    0.918329      1     inc\n",
      "1  1353.302002  354.651672  1475.096069  624.604919    0.884575      0  canine\n",
      "2   975.104675  416.585876  1077.980347  673.588989    0.864827      0  canine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\josem/.cache\\torch\\hub\\ultralytics_yolov5_master\\models\\common.py:906: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Línea media trazada en x=1223\n",
      "Guardado en: Output/prueba_original\\foto59_analizada.jpg\n",
      "\n",
      "Procesando: foto6.jpg\n",
      "\n",
      "=== RESULTADOS DE DETECCIÓN ===\n",
      "          xmin        ymin         xmax        ymax  confidence  class    name\n",
      "0  1054.666992  456.421082  1248.268188  791.907471    0.968930      1     inc\n",
      "1  1266.801636  375.279694  1375.919556  602.106873    0.917142      0  canine\n",
      "2   934.522766  353.759644  1035.254761  565.804565    0.905287      0  canine\n",
      "Línea media trazada en x=1151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\josem/.cache\\torch\\hub\\ultralytics_yolov5_master\\models\\common.py:906: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guardado en: Output/prueba_original\\foto6_analizada.jpg\n",
      "\n",
      "Procesando: foto60.jpg\n",
      "\n",
      "=== RESULTADOS DE DETECCIÓN ===\n",
      "          xmin        ymin         xmax        ymax  confidence  class    name\n",
      "0  1321.598511  392.686401  1429.510010  565.661926    0.901401      0  canine\n",
      "1   969.295959  381.223633  1082.441162  537.792297    0.869506      0  canine\n",
      "No se detectaron incisivos; no se puede trazar la línea media.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\josem/.cache\\torch\\hub\\ultralytics_yolov5_master\\models\\common.py:906: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Procesando: foto61.jpg\n",
      "\n",
      "=== RESULTADOS DE DETECCIÓN ===\n",
      "          xmin        ymin         xmax        ymax  confidence  class    name\n",
      "0   996.240906  348.794495  1105.938965  553.623474    0.922780      0  canine\n",
      "1  1120.455200  451.420959  1318.189941  805.204529    0.918827      1     inc\n",
      "2  1334.955811  366.149658  1457.786255  570.393555    0.903688      0  canine\n",
      "Línea media trazada en x=1219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\josem/.cache\\torch\\hub\\ultralytics_yolov5_master\\models\\common.py:906: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guardado en: Output/prueba_original\\foto61_analizada.jpg\n",
      "\n",
      "Procesando: foto62.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\josem/.cache\\torch\\hub\\ultralytics_yolov5_master\\models\\common.py:906: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n",
      "C:\\Users\\josem/.cache\\torch\\hub\\ultralytics_yolov5_master\\models\\common.py:906: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== RESULTADOS DE DETECCIÓN ===\n",
      "          xmin        ymin         xmax        ymax  confidence  class    name\n",
      "0   977.245117  317.970886  1115.615356  591.651978    0.922402      0  canine\n",
      "1  1314.440308  308.450989  1441.635010  572.620789    0.908586      0  canine\n",
      "No se detectaron incisivos; no se puede trazar la línea media.\n",
      "\n",
      "Procesando: foto63.jpg\n",
      "\n",
      "=== RESULTADOS DE DETECCIÓN ===\n",
      "          xmin        ymin         xmax        ymax  confidence  class    name\n",
      "0  1305.655884  374.836273  1420.819946  592.265137    0.907073      0  canine\n",
      "1   987.914001  358.027588  1104.044678  539.176392    0.861632      0  canine\n",
      "No se detectaron incisivos; no se puede trazar la línea media.\n",
      "\n",
      "Procesando: foto64.jpg\n",
      "\n",
      "=== RESULTADOS DE DETECCIÓN ===\n",
      "          xmin        ymin         xmax        ymax  confidence  class    name\n",
      "0  1002.537903  354.938568  1152.190186  632.174622    0.912625      0  canine\n",
      "1  1149.703369  537.831421  1324.005371  766.899841    0.904947      1     inc\n",
      "Línea media trazada en x=1236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\josem/.cache\\torch\\hub\\ultralytics_yolov5_master\\models\\common.py:906: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guardado en: Output/prueba_original\\foto64_analizada.jpg\n",
      "\n",
      "Procesando: foto65.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\josem/.cache\\torch\\hub\\ultralytics_yolov5_master\\models\\common.py:906: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== RESULTADOS DE DETECCIÓN ===\n",
      "          xmin        ymin         xmax        ymax  confidence  class    name\n",
      "0  1090.354492  475.052826  1271.102051  785.505493    0.929180      1     inc\n",
      "1   979.008972  348.111938  1086.337891  589.116821    0.900341      0  canine\n",
      "2  1275.521729  371.530243  1385.262695  607.667725    0.885150      0  canine\n",
      "Línea media trazada en x=1180\n",
      "Guardado en: Output/prueba_original\\foto65_analizada.jpg\n",
      "\n",
      "Procesando: foto66.jpg\n",
      "\n",
      "=== RESULTADOS DE DETECCIÓN ===\n",
      "          xmin        ymin         xmax        ymax  confidence  class    name\n",
      "0  1039.398804  389.280975  1191.173584  567.550476    0.906609      0  canine\n",
      "1  1200.330200  457.570099  1405.751587  773.306091    0.891435      1     inc\n",
      "2  1430.470703  372.470245  1569.634033  558.365479    0.874207      0  canine\n",
      "Línea media trazada en x=1302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\josem/.cache\\torch\\hub\\ultralytics_yolov5_master\\models\\common.py:906: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guardado en: Output/prueba_original\\foto66_analizada.jpg\n",
      "\n",
      "Procesando: foto67.jpg\n",
      "\n",
      "=== RESULTADOS DE DETECCIÓN ===\n",
      "          xmin        ymin         xmax        ymax  confidence  class    name\n",
      "0  1151.685791  452.440491  1331.890747  771.026184    0.914114      1     inc\n",
      "1   993.839417  389.160553  1145.667603  654.303223    0.900737      0  canine\n",
      "2  1353.891846  372.129547  1493.846191  666.023743    0.863372      0  canine\n",
      "Línea media trazada en x=1241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\josem/.cache\\torch\\hub\\ultralytics_yolov5_master\\models\\common.py:906: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guardado en: Output/prueba_original\\foto67_analizada.jpg\n",
      "\n",
      "Procesando: foto68.jpg\n",
      "\n",
      "=== RESULTADOS DE DETECCIÓN ===\n",
      "          xmin        ymin         xmax        ymax  confidence  class    name\n",
      "0  1142.081421  451.817505  1317.398682  776.874695    0.951453      1     inc\n",
      "1  1021.118774  333.467865  1139.236694  588.679626    0.918068      0  canine\n",
      "2  1311.655029  323.839294  1439.791016  574.023499    0.887350      0  canine\n",
      "Línea media trazada en x=1229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\josem/.cache\\torch\\hub\\ultralytics_yolov5_master\\models\\common.py:906: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guardado en: Output/prueba_original\\foto68_analizada.jpg\n",
      "\n",
      "Procesando: foto69.jpg\n",
      "\n",
      "=== RESULTADOS DE DETECCIÓN ===\n",
      "          xmin        ymin         xmax        ymax  confidence  class    name\n",
      "0  1245.082520  353.280914  1328.194214  564.147522    0.891512      0  canine\n",
      "1   968.191895  357.156677  1062.864746  557.703613    0.884704      0  canine\n",
      "2  1071.654419  501.030273  1232.898926  774.877808    0.870813      1     inc\n",
      "Línea media trazada en x=1151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\josem/.cache\\torch\\hub\\ultralytics_yolov5_master\\models\\common.py:906: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guardado en: Output/prueba_original\\foto69_analizada.jpg\n",
      "\n",
      "Procesando: foto7.jpg\n",
      "\n",
      "=== RESULTADOS DE DETECCIÓN ===\n",
      "          xmin        ymin         xmax        ymax  confidence  class    name\n",
      "0  1146.297729  453.536865  1304.611694  776.963745    0.918875      1     inc\n",
      "1  1006.621765  310.157501  1138.348999  553.731262    0.915339      0  canine\n",
      "2  1303.011353  326.116913  1433.579224  584.994263    0.900404      0  canine\n",
      "Línea media trazada en x=1225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\josem/.cache\\torch\\hub\\ultralytics_yolov5_master\\models\\common.py:906: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guardado en: Output/prueba_original\\foto7_analizada.jpg\n",
      "\n",
      "Procesando: foto70.jpg\n",
      "\n",
      "=== RESULTADOS DE DETECCIÓN ===\n",
      "          xmin        ymin         xmax        ymax  confidence  class    name\n",
      "0  1107.373901  440.109344  1291.906616  784.927917    0.960703      1     inc\n",
      "1  1311.738892  329.059662  1477.706665  598.038147    0.917815      0  canine\n",
      "2   965.380249  336.474426  1104.240112  602.301392    0.895944      0  canine\n",
      "Línea media trazada en x=1199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\josem/.cache\\torch\\hub\\ultralytics_yolov5_master\\models\\common.py:906: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guardado en: Output/prueba_original\\foto70_analizada.jpg\n",
      "\n",
      "Procesando: foto8.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\josem/.cache\\torch\\hub\\ultralytics_yolov5_master\\models\\common.py:906: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== RESULTADOS DE DETECCIÓN ===\n",
      "          xmin        ymin         xmax        ymax  confidence  class    name\n",
      "0   987.954834  347.496857  1104.428589  597.353149    0.913747      0  canine\n",
      "1  1131.034302  439.322327  1313.839355  782.083374    0.900689      1     inc\n",
      "2  1327.359619  334.889954  1466.104492  581.974731    0.859410      0  canine\n",
      "Línea media trazada en x=1222\n",
      "Guardado en: Output/prueba_original\\foto8_analizada.jpg\n",
      "\n",
      "Procesando: foto9.jpg\n",
      "\n",
      "=== RESULTADOS DE DETECCIÓN ===\n",
      "          xmin        ymin         xmax        ymax  confidence  class    name\n",
      "0  1031.535767  470.126160  1208.693726  765.650269    0.935185      1     inc\n",
      "1  1198.192749  348.578857  1317.372192  558.559143    0.914089      0  canine\n",
      "2   934.830994  341.247498  1037.601562  548.331726    0.852861      0  canine\n",
      "Línea media trazada en x=1119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\josem/.cache\\torch\\hub\\ultralytics_yolov5_master\\models\\common.py:906: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guardado en: Output/prueba_original\\foto9_analizada.jpg\n"
     ]
    }
   ],
   "source": [
    "# ======================================================================================================\n",
    "# Experimento 03: Medición de la proyección de los ángulos de los caninos sobre la línea media central\n",
    "# Se utilizan dos modelos\n",
    "# 1) Un modelo U-Net para segmentar la forma del canino (máscara)\n",
    "# 2) Un modelo YoloV5 para detectar la posición de los caninos e incisivos centrales\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "import math\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "from tooth_shape_model_unet import UNet\n",
    "from torchvision import transforms\n",
    "from PIL import Image \n",
    "\n",
    "\n",
    "# ======================================================================\n",
    "# Modelo U-Net para segmentación de caninos (obtener la forma del canino, para trazar la línea sobre él)\n",
    "\n",
    "IMG_HEIGHT = 256\n",
    "IMG_WIDTH = 256\n",
    "NUM_CLASSES = 3  # fondo, canino izquierdo, canino derecho\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "shape_unet = UNet(num_classes=NUM_CLASSES).to(device)\n",
    "shape_unet.load_state_dict(torch.load('models/tooth_shape_unet.pth', map_location=device))\n",
    "shape_unet.eval()\n",
    "\n",
    "infer_transform = transforms.Compose([\n",
    "    transforms.Resize((IMG_HEIGHT, IMG_WIDTH)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# ======================================================================\n",
    "# Modelo pre-entrenado (YoloV5) para la detección posicional de caninos e incisivos centrales\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = torch.hub.load(\n",
    "    'ultralytics/yolov5', \n",
    "    'custom',\n",
    "    path='models/tooth_detection.pt',\n",
    "    force_reload=True\n",
    ").to(device)\n",
    "\n",
    "# Umbral de confianza de detección posicional de caninos\n",
    "CONF_THRESHOLD = 0.85\n",
    "model.conf = CONF_THRESHOLD\n",
    "print(f\"Umbral de confianza ajustado a: {CONF_THRESHOLD}\")\n",
    "\n",
    "def calculate_line_intersection(line1_p1, line1_p2, line2_p1, line2_p2):\n",
    "    \"\"\"\n",
    "    Calcula el punto de intersección entre dos líneas definidas por dos puntos cada una.\n",
    "    Si las líneas son paralelas o no se intersectan dentro de los límites de la imagen, devuelve None.\n",
    "    \n",
    "    Args:\n",
    "        line1_p1, line1_p2: Puntos que definen la primera línea\n",
    "        line2_p1, line2_p2: Puntos que definen la segunda línea\n",
    "        \n",
    "    Returns:\n",
    "        tuple: Coordenadas (x, y) del punto de intersección o None si no hay intersección\n",
    "    \"\"\"\n",
    "    # Línea 1: (x1, y1) a (x2, y2)\n",
    "    x1, y1 = line1_p1\n",
    "    x2, y2 = line1_p2\n",
    "    \n",
    "    # Línea 2: (x3, y3) a (x4, y4)\n",
    "    x3, y3 = line2_p1\n",
    "    x4, y4 = line2_p2\n",
    "    \n",
    "    # Calcular denominador para verificar si las líneas son paralelas\n",
    "    denom = (y4 - y3) * (x2 - x1) - (x4 - x3) * (y2 - y1)\n",
    "    \n",
    "    if denom == 0:  # Líneas paralelas\n",
    "        return None\n",
    "    \n",
    "    # Calcular el punto de intersección\n",
    "    ua = ((x4 - x3) * (y1 - y3) - (y4 - y3) * (x1 - x3)) / denom\n",
    "    \n",
    "    # Punto de intersección\n",
    "    x = x1 + ua * (x2 - x1)\n",
    "    y = y1 + ua * (y2 - y1)\n",
    "    \n",
    "    return (int(x), int(y))\n",
    "\n",
    "def extend_line_to_boundaries(point1, point2, img_width, img_height, midline_x=None):\n",
    "    \"\"\"\n",
    "    Extiende una línea definida por dos puntos hasta los límites de la imagen o hasta intersectar con la línea media.\n",
    "    \n",
    "    Args:\n",
    "        point1 (tuple): Coordenadas (x, y) del primer punto.\n",
    "        point2 (tuple): Coordenadas (x, y) del segundo punto.\n",
    "        img_width (int): Ancho de la imagen.\n",
    "        img_height (int): Alto de la imagen.\n",
    "        midline_x (int, opcional): Coordenada x de la línea media. Si se proporciona, la línea se extenderá hasta esta línea.\n",
    "        \n",
    "    Returns:\n",
    "        tuple: Un par de tuplas con las coordenadas de los puntos extendidos (p1_extended, p2_extended).\n",
    "    \"\"\"\n",
    "    x1, y1 = point1\n",
    "    x2, y2 = point2\n",
    "    \n",
    "    # Si los puntos son iguales, no se puede definir una dirección\n",
    "    if x1 == x2 and y1 == y2:\n",
    "        return point1, point2\n",
    "    \n",
    "    # Calcular la dirección de la línea\n",
    "    dx = x2 - x1\n",
    "    dy = y2 - y1\n",
    "    \n",
    "    # Si la línea es vertical\n",
    "    if dx == 0:\n",
    "        # Extender hasta los bordes superior e inferior\n",
    "        return (x1, 0), (x1, img_height)\n",
    "    \n",
    "    # Calcular la pendiente y el intercepto\n",
    "    m = dy / dx\n",
    "    b = y1 - m * x1\n",
    "    \n",
    "    # Puntos extendidos\n",
    "    extended_points = []\n",
    "    \n",
    "    # Si hay una línea media definida, calcular la intersección con ella\n",
    "    if midline_x is not None:\n",
    "        # Calcular el punto de intersección con la línea media\n",
    "        y_intersect = m * midline_x + b\n",
    "        \n",
    "        # Verificar si la intersección está dentro de los límites de la imagen\n",
    "        if 0 <= y_intersect <= img_height:\n",
    "            # Determinar en qué lado de la línea media está el punto original\n",
    "            if (x1 < midline_x and x2 < midline_x) or (x1 > midline_x and x2 > midline_x):\n",
    "                # Ambos puntos están en el mismo lado de la línea media\n",
    "                # Extender hasta la línea media en una dirección\n",
    "                if x1 < midline_x:\n",
    "                    extended_points.append((midline_x, int(y_intersect)))\n",
    "                else:\n",
    "                    extended_points.append((midline_x, int(y_intersect)))\n",
    "            elif (x1 < midline_x and x2 > midline_x) or (x1 > midline_x and x2 < midline_x):\n",
    "                # No es necesario extender hasta la línea media\n",
    "                pass\n",
    "    \n",
    "    # Intersecciones con los bordes de la imagen\n",
    "    \n",
    "    # Intersección con y=0 (borde superior)\n",
    "    if abs(m) > 0.0001:  # No es una línea horizontal\n",
    "        x_top = (0 - b) / m\n",
    "        if 0 <= x_top <= img_width:\n",
    "            extended_points.append((int(x_top), 0))\n",
    "    \n",
    "    # Intersección con y=img_height (borde inferior)\n",
    "    if abs(m) > 0.0001:  # No es una línea horizontal\n",
    "        x_bottom = (img_height - b) / m\n",
    "        if 0 <= x_bottom <= img_width:\n",
    "            extended_points.append((int(x_bottom), img_height))\n",
    "    \n",
    "    # Intersección con x=0 (borde izquierdo)\n",
    "    y_left = b\n",
    "    if 0 <= y_left <= img_height:\n",
    "        extended_points.append((0, int(y_left)))\n",
    "    \n",
    "    # Intersección con x=img_width (borde derecho)\n",
    "    y_right = m * img_width + b\n",
    "    if 0 <= y_right <= img_height:\n",
    "        extended_points.append((img_width, int(y_right)))\n",
    "    \n",
    "    # Si no hay suficientes puntos de intersección, usar los puntos originales\n",
    "    if len(extended_points) < 2:\n",
    "        return point1, point2\n",
    "    \n",
    "    # Ordenar los puntos extendidos según su distancia desde el punto medio entre p1 y p2\n",
    "    midpoint = ((x1 + x2) / 2, (y1 + y2) / 2)\n",
    "    \n",
    "    # Si estamos del lado izquierdo de la línea media y queremos extender hacia la línea media\n",
    "    if midline_x is not None and (x1 < midline_x and x2 < midline_x):\n",
    "        # Encontrar el punto más cercano al borde y el punto más cercano a la línea media\n",
    "        points_sorted = sorted(extended_points, key=lambda p: p[0])  # Ordenar por coordenada x\n",
    "        return points_sorted[0], points_sorted[-1]  # El primero es el más a la izquierda, el último es el más a la derecha\n",
    "    \n",
    "    # Si estamos del lado derecho de la línea media y queremos extender hacia la línea media\n",
    "    elif midline_x is not None and (x1 > midline_x and x2 > midline_x):\n",
    "        # Encontrar el punto más cercano al borde y el punto más cercano a la línea media\n",
    "        points_sorted = sorted(extended_points, key=lambda p: p[0], reverse=True)  # Ordenar por coordenada x (reverso)\n",
    "        return points_sorted[0], points_sorted[-1]  # El primero es el más a la derecha, el último es el más a la izquierda\n",
    "    \n",
    "    # En otros casos, simplemente usar las dos intersecciones más alejadas entre sí\n",
    "    else:\n",
    "        # Calcular todas las combinaciones de distancias entre puntos\n",
    "        max_dist = 0\n",
    "        p1_ext, p2_ext = extended_points[0], extended_points[1]\n",
    "        \n",
    "        for i in range(len(extended_points)):\n",
    "            for j in range(i + 1, len(extended_points)):\n",
    "                dist = math.sqrt((extended_points[i][0] - extended_points[j][0])**2 + \n",
    "                                (extended_points[i][1] - extended_points[j][1])**2)\n",
    "                if dist > max_dist:\n",
    "                    max_dist = dist\n",
    "                    p1_ext, p2_ext = extended_points[i], extended_points[j]\n",
    "        \n",
    "        return p1_ext, p2_ext\n",
    "\n",
    "\n",
    "def get_corners(detection, side):\n",
    "    if side == 'izq':\n",
    "        return (int(detection['xmax']), int(detection['ymax'])), (int(detection['xmin']), int(detection['ymin']))\n",
    "    elif side == 'der':\n",
    "        return (int(detection['xmin']), int(detection['ymax'])), (int(detection['xmax']), int(detection['ymin']))\n",
    "    else:   \n",
    "        raise ValueError(\"Lado no válido. Debe ser 'izq' o 'der'.\")\n",
    "\n",
    "\n",
    "def segment_full_and_crop(orig_img, roi_coords):\n",
    "    # Segmenta toda la imagen y recorta ROI\n",
    "    img_rgb = cv2.cvtColor(orig_img, cv2.COLOR_BGR2RGB)\n",
    "    pil = Image.fromarray(img_rgb)\n",
    "    x = infer_transform(pil).unsqueeze(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        logits = shape_unet(x)\n",
    "        probs  = torch.softmax(logits, dim=1)[0]  # [3,H,W]\n",
    "\n",
    "    # si side=='left'\n",
    "    ch = probs[1] if side=='left' else probs[2]\n",
    "    heatmap = (ch.cpu().numpy() * 255).astype(np.uint8)\n",
    "    h, w = orig_img.shape[:2]\n",
    "    heatmap_full = cv2.resize(heatmap, (w, h), interpolation=cv2.INTER_LINEAR)\n",
    "    cv2.imwrite(f\"debug/heat_full_{side}.png\", heatmap_full)\n",
    "    chan = probs[1] if side=='left' else probs[2]\n",
    "    mask = (chan.cpu().numpy() > 0.03).astype(np.uint8) * 255\n",
    "    # redimensionar a full-res\n",
    "    h,w = orig_img.shape[:2]\n",
    "    mask_full = cv2.resize(mask,(w,h),interpolation=cv2.INTER_NEAREST)\n",
    "    # recortar\n",
    "    # x1,y1,x2,y2 = roi_coords\n",
    "    return mask_full\n",
    "\n",
    "\n",
    "def calculate_angle(line_p1, line_p2, vertical_line_x):\n",
    "    \"\"\"\n",
    "    Calcula el ángulo entre una línea definida por dos puntos y una línea vertical.\n",
    "    \n",
    "    Args:\n",
    "        line_p1 (tuple): Primer punto de la línea.\n",
    "        line_p2 (tuple): Segundo punto de la línea.\n",
    "        vertical_line_x (int): Coordenada x de la línea vertical.\n",
    "        \n",
    "    Returns:\n",
    "        float: Ángulo en grados entre las líneas.\n",
    "    \"\"\"\n",
    "    # Verificar que los puntos no sean iguales\n",
    "    if line_p1[0] == line_p2[0] and line_p1[1] == line_p2[1]:\n",
    "        return 0  # No se puede calcular el ángulo si los puntos son iguales\n",
    "    \n",
    "    # Vector de la línea\n",
    "    vector_line = (line_p2[0] - line_p1[0], line_p2[1] - line_p1[1])\n",
    "    \n",
    "    # Vector de la línea vertical (0, 1) normalizado\n",
    "    vector_vertical = (0, 1)\n",
    "    \n",
    "    # Calcular el ángulo entre los vectores usando el producto punto\n",
    "    # Normalizar los vectores\n",
    "    magnitude_line = math.sqrt(vector_line[0]**2 + vector_line[1]**2)\n",
    "    \n",
    "    if magnitude_line == 0:\n",
    "        return 0\n",
    "    \n",
    "    unit_vector_line = (vector_line[0] / magnitude_line, vector_line[1] / magnitude_line)\n",
    "    \n",
    "    # Producto punto de los vectores unitarios\n",
    "    dot_product = unit_vector_line[0] * vector_vertical[0] + unit_vector_line[1] * vector_vertical[1]\n",
    "    \n",
    "    # Asegurarse de que el producto punto esté en el rango [-1, 1]\n",
    "    dot_product = max(-1.0, min(1.0, dot_product))\n",
    "    \n",
    "    # Calcular el ángulo en radianes y convertirlo a grados\n",
    "    angle_rad = math.acos(dot_product)\n",
    "    angle_deg = math.degrees(angle_rad)\n",
    "    \n",
    "    # Determinar la dirección del ángulo (positivo o negativo)\n",
    "    # Si el punto p2 está a la derecha de la línea vertical, el ángulo es positivo\n",
    "    # Si está a la izquierda, el ángulo es negativo\n",
    "    direction = 1 if (line_p1[0] < vertical_line_x and line_p2[0] > vertical_line_x) or \\\n",
    "                    (line_p1[0] > vertical_line_x and line_p2[0] < vertical_line_x and line_p1[1] > line_p2[1]) else -1\n",
    "    \n",
    "    # Ajustar el ángulo según el cuadrante\n",
    "    if unit_vector_line[0] < 0:\n",
    "        angle_deg = 180 - angle_deg\n",
    "    \n",
    "    # Asegurarse de que el ángulo esté entre 0 y 180 grados\n",
    "    if angle_deg > 90:\n",
    "        angle_deg = 180 - angle_deg\n",
    "        \n",
    "    return angle_deg * direction\n",
    "\n",
    "def process_and_draw_canine(det, orig_img, side, inc_center_x=None):\n",
    "    coords = (int(det['xmin']), int(det['ymin']), int(det['xmax']), int(det['ymax']))\n",
    "    roi = orig_img[coords[1]:coords[3], coords[0]:coords[2]]\n",
    "    # 1) Segmentar\n",
    "    mask_roi = segment_full_and_crop(roi, coords)\n",
    "    cv2.imwrite(f\"debug/mask_roi_{side}.png\", mask_roi)\n",
    "    # 2) Extraer contorno\n",
    "    cnts,_ = cv2.findContours(mask_roi,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\n",
    "    if not cnts: return orig_img\n",
    "    contour = max(cnts, key=cv2.contourArea).reshape(-1,2).astype(np.float32)\n",
    "    # 3) PCA\n",
    "    mean,vecs,_ = cv2.PCACompute2(contour, mean=None)\n",
    "    axis = vecs[0]\n",
    "    # 4) Extremos\n",
    "    dif = contour - mean\n",
    "    projs = dif.dot(axis.T)\n",
    "    p1 = tuple(contour[np.argmin(projs)].astype(int))\n",
    "    p2 = tuple(contour[np.argmax(projs)].astype(int))\n",
    "    # Ajustar a coords global\n",
    "    p1g = (p1[0]+coords[0], p1[1]+coords[1])\n",
    "    p2g = (p2[0]+coords[0], p2[1]+coords[1])\n",
    "    # 5) Dibujar\n",
    "    cv2.circle(orig_img, p1g, 4,(0,255,0),-1)\n",
    "    cv2.circle(orig_img, p2g, 4,(0,255,0),-1)\n",
    "    \n",
    "    # Extender la línea hasta los límites de la imagen o hasta la línea media\n",
    "    h, w = orig_img.shape[:2]\n",
    "    midline_x = inc_center_x if inc_center_x is not None else None\n",
    "    \n",
    "    # Extender la línea hasta la línea media o los límites de la imagen\n",
    "    exp1, exp2 = extend_line_to_boundaries(p1g, p2g, w, h, midline_x)\n",
    "    \n",
    "    # Dibujar la línea extendida\n",
    "    cv2.line(orig_img, exp1, exp2, (0,0,255), 2)\n",
    "    \n",
    "    # Sacar centro\n",
    "\n",
    "    # Si hay línea media, marcar la intersección\n",
    "    if midline_x is not None:\n",
    "        # Calcular la intersección con la línea media\n",
    "        midline_top = (midline_x, 0)\n",
    "        midline_bottom = (midline_x, h)\n",
    "        \n",
    "        intersection = calculate_line_intersection(exp1, exp2, midline_top, midline_bottom)\n",
    "        \n",
    "        if intersection:\n",
    "            # Dibujar un círculo en el punto de intersección\n",
    "            cv2.circle(orig_img, intersection, 6, (255, 0, 255), -1)\n",
    "            \n",
    "            # Calcular el ángulo entre la línea del canino y la línea media\n",
    "            angle = calculate_angle(exp1, exp2, midline_x)\n",
    "            \n",
    "            # Mostrar el ángulo en la imagen\n",
    "            angle_text = f\"Ángulo: {abs(angle):.1f}°\"\n",
    "            cv2.putText(orig_img, angle_text, \n",
    "                       (intersection[0] + 10, intersection[1] + 25), \n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 0, 255), 2)\n",
    "            \n",
    "            # Dibujar un arco para visualizar el ángulo\n",
    "            radius = 40\n",
    "            start_angle = 90  # Línea vertical (línea media)\n",
    "            \n",
    "            # Determinar la dirección del arco según el signo del ángulo\n",
    "            if angle < 0:\n",
    "                end_angle = 90 - abs(angle)\n",
    "            else:\n",
    "                end_angle = 90 + abs(angle)\n",
    "            \n",
    "            # Dibujar el arco\n",
    "            cv2.ellipse(orig_img, intersection, (radius, radius), \n",
    "                        0, min(start_angle, end_angle), max(start_angle, end_angle), \n",
    "                        (255, 0, 255), 2)\n",
    "            \n",
    "            cv2.putText(orig_img, f\"Intersección\", \n",
    "                       (intersection[0] + 10, intersection[1]), \n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 255), 2)\n",
    "    \n",
    "    return orig_img\n",
    "\n",
    "# Dibujar todas las detecciones con centros\n",
    "def draw_box(det):\n",
    "    if det['name'] not in ['inc', 'canine']:\n",
    "        x1, y1, x2, y2 = map(int, [det['xmin'], det['ymin'], det['xmax'], det['ymax']])\n",
    "        color = (0, 255, 255)\n",
    "        cv2.rectangle(orig, (x1, y1), (x2, y2), color, 2)\n",
    "        cv2.putText(orig, f\"{det['name']}: {det['confidence']:.2f}\", \n",
    "                   (x1, y1-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "        c = get_center(det)\n",
    "        cv2.circle(orig, c, 5, color, -1)\n",
    "        \n",
    "# =================================================================================================\n",
    "# =================================================================================================\n",
    "# =================================================================================================\n",
    "# Bloque principal\n",
    "\n",
    "input_folder = 'img_test/Lote1'       # cambia por tu carpeta de entrada real\n",
    "output_folder = 'Output/prueba_original'     # carpeta para guardar resultados\n",
    "\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "image_files = [f for f in os.listdir(input_folder) if f.lower().endswith(('.jpg', '.png', '.jpeg'))]\n",
    "\n",
    "def get_center(detection):\n",
    "    xmin, ymin, xmax, ymax = map(int, [detection['xmin'], detection['ymin'], \n",
    "                                      detection['xmax'], detection['ymax']])\n",
    "    cx = (xmin + xmax) // 2\n",
    "    cy = (ymin + ymax) // 2\n",
    "    return (cx, cy)\n",
    "for image_name in image_files:\n",
    "    img_path = os.path.join(input_folder, image_name)\n",
    "    img = cv2.imread(img_path)\n",
    "    \n",
    "    if img is None:\n",
    "        print(f\"ERROR: No se pudo leer la imagen: {image_name}\")\n",
    "        continue\n",
    "\n",
    "    print(f\"\\nProcesando: {image_name}\")\n",
    "    orig = img.copy()\n",
    "    height, width = img.shape[:2]\n",
    "\n",
    "    # Ejecutar detección con YOLO\n",
    "    results = model(img)\n",
    "    df = results.pandas().xyxy[0]  # xmin, ymin, xmax, ymax, confidence, class, name\n",
    "\n",
    "    print(\"\\n=== RESULTADOS DE DETECCIÓN ===\")\n",
    "    print(df)\n",
    "\n",
    "    # Detecciones de incisivos y caninos\n",
    "    incisor_detections = df[df['name'] == 'inc']\n",
    "    canines = df[df['name'] == 'canine']\n",
    "\n",
    "    # Línea media desde incisivos\n",
    "    inc_center = None\n",
    "    if len(incisor_detections) > 0:\n",
    "        best_inc = incisor_detections.sort_values('confidence', ascending=False).iloc[0]\n",
    "        inc_center = get_center(best_inc)\n",
    "        # Dibujar línea media\n",
    "        cv2.line(orig, (inc_center[0], 0), (inc_center[0], height), (0, 255, 0), 2)\n",
    "        cv2.putText(orig, 'Línea media', (inc_center[0] + 10, 30),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "        print(f\"Línea media trazada en x={inc_center[0]}\")\n",
    "    else:\n",
    "        print(\"No se detectaron incisivos; no se puede trazar la línea media.\")\n",
    "        continue  # no tiene sentido seguir si no hay línea media\n",
    "\n",
    "    # Procesamiento de caninos\n",
    "    for _, det in canines.iterrows():\n",
    "        center = get_center(det)\n",
    "        side = 'izq' if center[0] < inc_center[0] else 'der'\n",
    "\n",
    "        x1, y1, x2, y2 = map(int, [det['xmin'], det['ymin'], det['xmax'], det['ymax']])\n",
    "        color = (255, 0, 0) if side == 'izq' else (0, 0, 255)\n",
    "        cv2.rectangle(orig, (x1, y1), (x2, y2), color, 2)\n",
    "\n",
    "        orig = process_and_draw_canine(det, orig, side, inc_center[0])\n",
    "\n",
    "        cv2.putText(orig, f\"Canino {side}: {det['confidence']:.2f}\", \n",
    "                    (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "        cv2.circle(orig, center, 5, color, -1)\n",
    "\n",
    "    # Dibujar otras detecciones (no incisivos ni caninos)\n",
    "    for _, det in df.iterrows():\n",
    "        if det['name'] not in ['inc', 'canine']:\n",
    "            draw_box(det)\n",
    "\n",
    "    # Guardar imagen procesada\n",
    "    out_path = os.path.join(output_folder, f\"{os.path.splitext(image_name)[0]}_analizada.jpg\")\n",
    "    cv2.imwrite(out_path, orig)\n",
    "    print(f\"Guardado en: {out_path}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b8acf44",
   "metadata": {},
   "source": [
    "# CÓDIGO PARA EVALUAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c073de45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ffda7c8a",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
